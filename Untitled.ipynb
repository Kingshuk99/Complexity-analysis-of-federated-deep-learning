{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf071c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "from counter import scope\n",
    "from models_dict import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f04cd47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kings\\anaconda3\\envs\\python_programs\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------Forward Pass - Training------------------------------------------------------\n",
      "             Layer (type)     Output Shape     Params        Addition  Multiplication    Logical     Sq inv   Division\n",
      "======================================================================================================================\n",
      "                 Conv2d-1   [1, 6, 28, 28]        156         117,600         117,600          0          0          0\n",
      "                   ReLU-2   [1, 6, 28, 28]          0               0               0      4,704          0          0\n",
      "              MaxPool2d-3   [1, 6, 14, 14]          0               0               0      3,528          0          0\n",
      "                 Conv2d-4  [1, 16, 10, 10]      2,416         240,000         240,000          0          0          0\n",
      "                   ReLU-5  [1, 16, 10, 10]          0               0               0      1,600          0          0\n",
      "              MaxPool2d-6    [1, 16, 5, 5]          0               0               0      1,200          0          0\n",
      "                 Linear-7         [1, 120]     48,120          48,000          48,000          0          0          0\n",
      "                   ReLU-8         [1, 120]          0               0               0        120          0          0\n",
      "                 Linear-9          [1, 84]     10,164          10,080          10,080          0          0          0\n",
      "                  ReLU-10          [1, 84]          0               0               0         84          0          0\n",
      "                Linear-11          [1, 10]        850             840             840          0          0          0\n",
      "======================================================================================================================\n",
      "Total params: 61,706\n",
      "Total FLOPs: 844,276\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward pass size (MB): 0.03\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 0.09\n",
      "FLOPs size (GB): 0.00\n",
      "----------------------------------------------------------------\n",
      "-----------------------------------------Forward Pass - Inference-----------------------------------------------------\n",
      "             Layer (type)     Output Shape        Addition  Multiplication    Logical     Sq inv   Division\n",
      "======================================================================================================================\n",
      "                 Conv2d-1   [1, 6, 28, 28]         117,600         117,600          0          0          0\n",
      "                   ReLU-2   [1, 6, 28, 28]               0               0      4,704          0          0\n",
      "              MaxPool2d-3   [1, 6, 14, 14]               0               0      3,528          0          0\n",
      "                 Conv2d-4  [1, 16, 10, 10]         240,000         240,000          0          0          0\n",
      "                   ReLU-5  [1, 16, 10, 10]               0               0      1,600          0          0\n",
      "              MaxPool2d-6    [1, 16, 5, 5]               0               0      1,200          0          0\n",
      "                 Linear-7         [1, 120]          48,000          48,000          0          0          0\n",
      "                   ReLU-8         [1, 120]               0               0        120          0          0\n",
      "                 Linear-9          [1, 84]          10,080          10,080          0          0          0\n",
      "                  ReLU-10          [1, 84]               0               0         84          0          0\n",
      "                Linear-11          [1, 10]             840             840          0          0          0\n",
      "======================================================================================================================\n",
      "Total FLOPs: 844,276\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward pass size (MB): 0.03\n",
      "FLOPs size (GB): 0.00\n",
      "----------------------------------------------------------------\n",
      "-----------------------------------------------Backward Pass----------------------------------------------------------\n",
      "             Layer (type)     Output Shape        Addition  Multiplication    Logical     Sq inv   Division\n",
      "======================================================================================================================\n",
      "                Linear-11          [1, 10]             756           1,680          0          0          0\n",
      "                  ReLU-10          [1, 84]               0               0         84          0          0\n",
      "                 Linear-9          [1, 84]           9,960          20,160          0          0          0\n",
      "                   ReLU-8         [1, 120]               0               0        120          0          0\n",
      "                 Linear-7         [1, 120]          47,600          96,000          0          0          0\n",
      "              MaxPool2d-6    [1, 16, 5, 5]             400               0          0          0          0\n",
      "                   ReLU-5  [1, 16, 10, 10]               0               0      1,600          0          0\n",
      "                 Conv2d-4  [1, 16, 10, 10]         478,008         480,000          0          0          0\n",
      "              MaxPool2d-3   [1, 6, 14, 14]           1,176               0          0          0          0\n",
      "                   ReLU-2   [1, 6, 28, 28]               0               0      4,704          0          0\n",
      "                 Conv2d-1   [1, 6, 28, 28]         238,724         235,200          0          0          0\n",
      "======================================================================================================\n",
      "Total FLOPs: 1,616,172\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Backward pass size (MB): 0.03\n",
      "FLOPs size (GB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "  net = Lenet5()\n",
    "scope(net, input_size=(1, 32, 32), batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "796d52bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------Forward Pass - Training------------------------------------------------------\n",
      "             Layer (type)     Output Shape     Params        Addition  Multiplication    Logical     Sq inv   Division\n",
      "======================================================================================================================\n",
      "                 Conv2d-1  [32, 64, 112, 112]      9,408   3,750,756,352   3,776,446,464          0          0          0\n",
      "            BatchNorm2d-2  [32, 64, 112, 112]        128      51,380,288      77,070,720          0         64          0\n",
      "                   ReLU-3  [32, 64, 112, 112]          0               0               0 25,690,112          0          0\n",
      "              MaxPool2d-4  [32, 64, 56, 56]          0               0               0 51,380,224          0          0\n",
      "                 Conv2d-5  [32, 64, 56, 56]     36,864   3,692,953,600   3,699,376,128          0          0          0\n",
      "            BatchNorm2d-6  [32, 64, 56, 56]        128      12,845,120      19,267,968          0         64          0\n",
      "                   ReLU-7  [32, 64, 56, 56]          0               0               0  6,422,528          0          0\n",
      "                 Conv2d-8  [32, 64, 56, 56]     36,864   3,692,953,600   3,699,376,128          0          0          0\n",
      "            BatchNorm2d-9  [32, 64, 56, 56]        128      12,845,120      19,267,968          0         64          0\n",
      "                  ReLU-10  [32, 64, 56, 56]          0               0               0  6,422,528          0          0\n",
      "                Conv2d-11  [32, 64, 56, 56]     36,864   3,692,953,600   3,699,376,128          0          0          0\n",
      "           BatchNorm2d-12  [32, 64, 56, 56]        128      12,845,120      19,267,968          0         64          0\n",
      "                  ReLU-13  [32, 64, 56, 56]          0               0               0  6,422,528          0          0\n",
      "                Conv2d-14  [32, 64, 56, 56]     36,864   3,692,953,600   3,699,376,128          0          0          0\n",
      "           BatchNorm2d-15  [32, 64, 56, 56]        128      12,845,120      19,267,968          0         64          0\n",
      "                  ReLU-16  [32, 64, 56, 56]          0               0               0  6,422,528          0          0\n",
      "                Conv2d-17  [32, 128, 28, 28]     73,728   1,846,476,800   1,849,688,064          0          0          0\n",
      "           BatchNorm2d-18  [32, 128, 28, 28]        256       6,422,656       9,634,560          0        128          0\n",
      "                  ReLU-19  [32, 128, 28, 28]          0               0               0  3,211,264          0          0\n",
      "                Conv2d-20  [32, 128, 28, 28]    147,456   3,696,164,864   3,699,376,128          0          0          0\n",
      "           BatchNorm2d-21  [32, 128, 28, 28]        256       6,422,656       9,634,560          0        128          0\n",
      "                Conv2d-22  [32, 128, 28, 28]      8,192     202,309,632     205,520,896          0          0          0\n",
      "           BatchNorm2d-23  [32, 128, 28, 28]        256       6,422,656       9,634,560          0        128          0\n",
      "                  ReLU-24  [32, 128, 28, 28]          0               0               0  3,211,264          0          0\n",
      "                Conv2d-25  [32, 128, 28, 28]    147,456   3,696,164,864   3,699,376,128          0          0          0\n",
      "           BatchNorm2d-26  [32, 128, 28, 28]        256       6,422,656       9,634,560          0        128          0\n",
      "                  ReLU-27  [32, 128, 28, 28]          0               0               0  3,211,264          0          0\n",
      "                Conv2d-28  [32, 128, 28, 28]    147,456   3,696,164,864   3,699,376,128          0          0          0\n",
      "           BatchNorm2d-29  [32, 128, 28, 28]        256       6,422,656       9,634,560          0        128          0\n",
      "                  ReLU-30  [32, 128, 28, 28]          0               0               0  3,211,264          0          0\n",
      "                Conv2d-31  [32, 256, 14, 14]    294,912   1,848,082,432   1,849,688,064          0          0          0\n",
      "           BatchNorm2d-32  [32, 256, 14, 14]        512       3,211,520       4,818,432          0        256          0\n",
      "                  ReLU-33  [32, 256, 14, 14]          0               0               0  1,605,632          0          0\n",
      "                Conv2d-34  [32, 256, 14, 14]    589,824   3,697,770,496   3,699,376,128          0          0          0\n",
      "           BatchNorm2d-35  [32, 256, 14, 14]        512       3,211,520       4,818,432          0        256          0\n",
      "                Conv2d-36  [32, 256, 14, 14]     32,768     203,915,264     205,520,896          0          0          0\n",
      "           BatchNorm2d-37  [32, 256, 14, 14]        512       3,211,520       4,818,432          0        256          0\n",
      "                  ReLU-38  [32, 256, 14, 14]          0               0               0  1,605,632          0          0\n",
      "                Conv2d-39  [32, 256, 14, 14]    589,824   3,697,770,496   3,699,376,128          0          0          0\n",
      "           BatchNorm2d-40  [32, 256, 14, 14]        512       3,211,520       4,818,432          0        256          0\n",
      "                  ReLU-41  [32, 256, 14, 14]          0               0               0  1,605,632          0          0\n",
      "                Conv2d-42  [32, 256, 14, 14]    589,824   3,697,770,496   3,699,376,128          0          0          0\n",
      "           BatchNorm2d-43  [32, 256, 14, 14]        512       3,211,520       4,818,432          0        256          0\n",
      "                  ReLU-44  [32, 256, 14, 14]          0               0               0  1,605,632          0          0\n",
      "                Conv2d-45  [32, 512, 7, 7]  1,179,648   1,848,885,248   1,849,688,064          0          0          0\n",
      "           BatchNorm2d-46  [32, 512, 7, 7]      1,024       1,606,144       2,411,520          0        512          0\n",
      "                  ReLU-47  [32, 512, 7, 7]          0               0               0    802,816          0          0\n",
      "                Conv2d-48  [32, 512, 7, 7]  2,359,296   3,698,573,312   3,699,376,128          0          0          0\n",
      "           BatchNorm2d-49  [32, 512, 7, 7]      1,024       1,606,144       2,411,520          0        512          0\n",
      "                Conv2d-50  [32, 512, 7, 7]    131,072     204,718,080     205,520,896          0          0          0\n",
      "           BatchNorm2d-51  [32, 512, 7, 7]      1,024       1,606,144       2,411,520          0        512          0\n",
      "                  ReLU-52  [32, 512, 7, 7]          0               0               0    802,816          0          0\n",
      "                Conv2d-53  [32, 512, 7, 7]  2,359,296   3,698,573,312   3,699,376,128          0          0          0\n",
      "           BatchNorm2d-54  [32, 512, 7, 7]      1,024       1,606,144       2,411,520          0        512          0\n",
      "                  ReLU-55  [32, 512, 7, 7]          0               0               0    802,816          0          0\n",
      "                Conv2d-56  [32, 512, 7, 7]  2,359,296   3,698,573,312   3,699,376,128          0          0          0\n",
      "           BatchNorm2d-57  [32, 512, 7, 7]      1,024       1,606,144       2,411,520          0        512          0\n",
      "                  ReLU-58  [32, 512, 7, 7]          0               0               0    802,816          0          0\n",
      "     AdaptiveAvgPool2d-59  [32, 512, 1, 1]          0         786,432               0          0          0     16,384\n",
      "                Linear-60       [32, 1000]    513,000      16,384,000      16,384,000          0          0          0\n",
      "======================================================================================================================\n",
      "Total params: 11,689,512\n",
      "Total FLOPs: 116,544,689,664\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.59\n",
      "Forward pass size (MB): 456.40\n",
      "Params size (MB): 11.15\n",
      "Estimated Total Size (MB): 472.15\n",
      "FLOPs size (GB): 116.54\n",
      "----------------------------------------------------------------\n",
      "-----------------------------------------Forward Pass - Inference-----------------------------------------------------\n",
      "             Layer (type)     Output Shape        Addition  Multiplication    Logical     Sq inv   Division\n",
      "======================================================================================================================\n",
      "                 Conv2d-1  [32, 64, 112, 112]     117,211,136     118,013,952          0          0          0\n",
      "            BatchNorm2d-2  [32, 64, 112, 112]       3,211,392       1,605,760          0        128          0\n",
      "                   ReLU-3  [32, 64, 112, 112]               0               0    802,816          0          0\n",
      "              MaxPool2d-4  [32, 64, 56, 56]               0               0  1,605,632          0          0\n",
      "                 Conv2d-5  [32, 64, 56, 56]     115,404,800     115,605,504          0          0          0\n",
      "            BatchNorm2d-6  [32, 64, 56, 56]         802,944         401,536          0        128          0\n",
      "                   ReLU-7  [32, 64, 56, 56]               0               0    200,704          0          0\n",
      "                 Conv2d-8  [32, 64, 56, 56]     115,404,800     115,605,504          0          0          0\n",
      "            BatchNorm2d-9  [32, 64, 56, 56]         802,944         401,536          0        128          0\n",
      "                  ReLU-10  [32, 64, 56, 56]               0               0    200,704          0          0\n",
      "                Conv2d-11  [32, 64, 56, 56]     115,404,800     115,605,504          0          0          0\n",
      "           BatchNorm2d-12  [32, 64, 56, 56]         802,944         401,536          0        128          0\n",
      "                  ReLU-13  [32, 64, 56, 56]               0               0    200,704          0          0\n",
      "                Conv2d-14  [32, 64, 56, 56]     115,404,800     115,605,504          0          0          0\n",
      "           BatchNorm2d-15  [32, 64, 56, 56]         802,944         401,536          0        128          0\n",
      "                  ReLU-16  [32, 64, 56, 56]               0               0    200,704          0          0\n",
      "                Conv2d-17  [32, 128, 28, 28]      57,702,400      57,802,752          0          0          0\n",
      "           BatchNorm2d-18  [32, 128, 28, 28]         401,664         200,960          0        256          0\n",
      "                  ReLU-19  [32, 128, 28, 28]               0               0    100,352          0          0\n",
      "                Conv2d-20  [32, 128, 28, 28]     115,505,152     115,605,504          0          0          0\n",
      "           BatchNorm2d-21  [32, 128, 28, 28]         401,664         200,960          0        256          0\n",
      "                Conv2d-22  [32, 128, 28, 28]       6,322,176       6,422,528          0          0          0\n",
      "           BatchNorm2d-23  [32, 128, 28, 28]         401,664         200,960          0        256          0\n",
      "                  ReLU-24  [32, 128, 28, 28]               0               0    100,352          0          0\n",
      "                Conv2d-25  [32, 128, 28, 28]     115,505,152     115,605,504          0          0          0\n",
      "           BatchNorm2d-26  [32, 128, 28, 28]         401,664         200,960          0        256          0\n",
      "                  ReLU-27  [32, 128, 28, 28]               0               0    100,352          0          0\n",
      "                Conv2d-28  [32, 128, 28, 28]     115,505,152     115,605,504          0          0          0\n",
      "           BatchNorm2d-29  [32, 128, 28, 28]         401,664         200,960          0        256          0\n",
      "                  ReLU-30  [32, 128, 28, 28]               0               0    100,352          0          0\n",
      "                Conv2d-31  [32, 256, 14, 14]      57,752,576      57,802,752          0          0          0\n",
      "           BatchNorm2d-32  [32, 256, 14, 14]         201,216         100,864          0        512          0\n",
      "                  ReLU-33  [32, 256, 14, 14]               0               0     50,176          0          0\n",
      "                Conv2d-34  [32, 256, 14, 14]     115,555,328     115,605,504          0          0          0\n",
      "           BatchNorm2d-35  [32, 256, 14, 14]         201,216         100,864          0        512          0\n",
      "                Conv2d-36  [32, 256, 14, 14]       6,372,352       6,422,528          0          0          0\n",
      "           BatchNorm2d-37  [32, 256, 14, 14]         201,216         100,864          0        512          0\n",
      "                  ReLU-38  [32, 256, 14, 14]               0               0     50,176          0          0\n",
      "                Conv2d-39  [32, 256, 14, 14]     115,555,328     115,605,504          0          0          0\n",
      "           BatchNorm2d-40  [32, 256, 14, 14]         201,216         100,864          0        512          0\n",
      "                  ReLU-41  [32, 256, 14, 14]               0               0     50,176          0          0\n",
      "                Conv2d-42  [32, 256, 14, 14]     115,555,328     115,605,504          0          0          0\n",
      "           BatchNorm2d-43  [32, 256, 14, 14]         201,216         100,864          0        512          0\n",
      "                  ReLU-44  [32, 256, 14, 14]               0               0     50,176          0          0\n",
      "                Conv2d-45  [32, 512, 7, 7]      57,777,664      57,802,752          0          0          0\n",
      "           BatchNorm2d-46  [32, 512, 7, 7]         101,376          51,200          0      1,024          0\n",
      "                  ReLU-47  [32, 512, 7, 7]               0               0     25,088          0          0\n",
      "                Conv2d-48  [32, 512, 7, 7]     115,580,416     115,605,504          0          0          0\n",
      "           BatchNorm2d-49  [32, 512, 7, 7]         101,376          51,200          0      1,024          0\n",
      "                Conv2d-50  [32, 512, 7, 7]       6,397,440       6,422,528          0          0          0\n",
      "           BatchNorm2d-51  [32, 512, 7, 7]         101,376          51,200          0      1,024          0\n",
      "                  ReLU-52  [32, 512, 7, 7]               0               0     25,088          0          0\n",
      "                Conv2d-53  [32, 512, 7, 7]     115,580,416     115,605,504          0          0          0\n",
      "           BatchNorm2d-54  [32, 512, 7, 7]         101,376          51,200          0      1,024          0\n",
      "                  ReLU-55  [32, 512, 7, 7]               0               0     25,088          0          0\n",
      "                Conv2d-56  [32, 512, 7, 7]     115,580,416     115,605,504          0          0          0\n",
      "           BatchNorm2d-57  [32, 512, 7, 7]         101,376          51,200          0      1,024          0\n",
      "                  ReLU-58  [32, 512, 7, 7]               0               0     25,088          0          0\n",
      "     AdaptiveAvgPool2d-59  [32, 512, 1, 1]          24,576               0          0          0        512\n",
      "                Linear-60       [32, 1000]         512,000         512,000          0          0          0\n",
      "======================================================================================================================\n",
      "Total FLOPs: 3,644,532,864\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.59\n",
      "Forward pass size (MB): 456.40\n",
      "FLOPs size (GB): 3.64\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kings\\anaconda3\\envs\\python_programs\\lib\\site-packages\\torch\\nn\\modules\\module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------Backward Pass----------------------------------------------------------\n",
      "             Layer (type)     Output Shape        Addition  Multiplication    Logical     Sq inv   Division\n",
      "======================================================================================================================\n",
      "                Linear-60       [32, 1000]      16,367,616      32,768,000          0          0          0\n",
      "     AdaptiveAvgPool2d-59  [32, 512, 1, 1]         802,816               0          0          0     16,384\n",
      "                  ReLU-58  [32, 512, 7, 7]               0               0    802,816          0          0\n",
      "           BatchNorm2d-57  [32, 512, 7, 7]       6,420,480       5,623,808          0          0          0\n",
      "                Conv2d-56  [32, 512, 7, 7]   7,322,451,968   7,398,752,256          0          0          0\n",
      "                  ReLU-55  [32, 512, 7, 7]               0               0    802,816          0          0\n",
      "           BatchNorm2d-54  [32, 512, 7, 7]       6,420,480       5,623,808          0          0          0\n",
      "                Conv2d-53  [32, 512, 7, 7]   7,322,451,968   7,398,752,256          0          0          0\n",
      "                  ReLU-52  [32, 512, 7, 7]               0               0    802,816          0          0\n",
      "           BatchNorm2d-51  [32, 512, 7, 7]       6,420,480       5,623,808          0          0          0\n",
      "                Conv2d-50  [32, 512, 7, 7]     405,241,856     411,041,792          0          0          0\n",
      "           BatchNorm2d-49  [32, 512, 7, 7]       6,420,480       5,623,808          0          0          0\n",
      "                Conv2d-48  [32, 512, 7, 7]   7,322,451,968   7,398,752,256          0          0          0\n",
      "                  ReLU-47  [32, 512, 7, 7]               0               0    802,816          0          0\n",
      "           BatchNorm2d-46  [32, 512, 7, 7]       6,420,480       5,623,808          0          0          0\n",
      "                Conv2d-45  [32, 512, 7, 7]   3,660,021,760   3,699,376,128          0          0          0\n",
      "                  ReLU-44  [32, 256, 14, 14]               0               0  1,605,632          0          0\n",
      "           BatchNorm2d-43  [32, 256, 14, 14]      12,844,032      11,241,472          0          0          0\n",
      "                Conv2d-42  [32, 256, 14, 14]   7,378,272,256   7,398,752,256          0          0          0\n",
      "                  ReLU-41  [32, 256, 14, 14]               0               0  1,605,632          0          0\n",
      "           BatchNorm2d-40  [32, 256, 14, 14]      12,844,032      11,241,472          0          0          0\n",
      "                Conv2d-39  [32, 256, 14, 14]   7,378,272,256   7,398,752,256          0          0          0\n",
      "                  ReLU-38  [32, 256, 14, 14]               0               0  1,605,632          0          0\n",
      "           BatchNorm2d-37  [32, 256, 14, 14]      12,844,032      11,241,472          0          0          0\n",
      "                Conv2d-36  [32, 256, 14, 14]     406,781,952     411,041,792          0          0          0\n",
      "           BatchNorm2d-35  [32, 256, 14, 14]      12,844,032      11,241,472          0          0          0\n",
      "                Conv2d-34  [32, 256, 14, 14]   7,378,272,256   7,398,752,256          0          0          0\n",
      "                  ReLU-33  [32, 256, 14, 14]               0               0  1,605,632          0          0\n",
      "           BatchNorm2d-32  [32, 256, 14, 14]      12,844,032      11,241,472          0          0          0\n",
      "                Conv2d-31  [32, 256, 14, 14]   3,686,727,680   3,699,376,128          0          0          0\n",
      "                  ReLU-30  [32, 128, 28, 28]               0               0  3,211,264          0          0\n",
      "           BatchNorm2d-29  [32, 128, 28, 28]      25,689,600      22,479,872          0          0          0\n",
      "                Conv2d-28  [32, 128, 28, 28]   7,390,822,400   7,398,752,256          0          0          0\n",
      "                  ReLU-27  [32, 128, 28, 28]               0               0  3,211,264          0          0\n",
      "           BatchNorm2d-26  [32, 128, 28, 28]      25,689,600      22,479,872          0          0          0\n",
      "                Conv2d-25  [32, 128, 28, 28]   7,390,822,400   7,398,752,256          0          0          0\n",
      "                  ReLU-24  [32, 128, 28, 28]               0               0  3,211,264          0          0\n",
      "           BatchNorm2d-23  [32, 128, 28, 28]      25,689,600      22,479,872          0          0          0\n",
      "                Conv2d-22  [32, 128, 28, 28]     404,357,120     411,041,792          0          0          0\n",
      "           BatchNorm2d-21  [32, 128, 28, 28]      25,689,600      22,479,872          0          0          0\n",
      "                Conv2d-20  [32, 128, 28, 28]   7,390,822,400   7,398,752,256          0          0          0\n",
      "                  ReLU-19  [32, 128, 28, 28]               0               0  3,211,264          0          0\n",
      "           BatchNorm2d-18  [32, 128, 28, 28]      25,689,600      22,479,872          0          0          0\n",
      "                Conv2d-17  [32, 128, 28, 28]   3,690,594,304   3,699,376,128          0          0          0\n",
      "                  ReLU-16  [32, 64, 56, 56]               0               0  6,422,528          0          0\n",
      "           BatchNorm2d-15  [32, 64, 56, 56]      51,379,968      44,958,208          0          0          0\n",
      "                Conv2d-14  [32, 64, 56, 56]   7,391,150,080   7,398,752,256          0          0          0\n",
      "                  ReLU-13  [32, 64, 56, 56]               0               0  6,422,528          0          0\n",
      "           BatchNorm2d-12  [32, 64, 56, 56]      51,379,968      44,958,208          0          0          0\n",
      "                Conv2d-11  [32, 64, 56, 56]   7,391,150,080   7,398,752,256          0          0          0\n",
      "                  ReLU-10  [32, 64, 56, 56]               0               0  6,422,528          0          0\n",
      "            BatchNorm2d-9  [32, 64, 56, 56]      51,379,968      44,958,208          0          0          0\n",
      "                 Conv2d-8  [32, 64, 56, 56]   7,391,150,080   7,398,752,256          0          0          0\n",
      "                   ReLU-7  [32, 64, 56, 56]               0               0  6,422,528          0          0\n",
      "            BatchNorm2d-6  [32, 64, 56, 56]      51,379,968      44,958,208          0          0          0\n",
      "                 Conv2d-5  [32, 64, 56, 56]   7,391,150,080   7,398,752,256          0          0          0\n",
      "              MaxPool2d-4  [32, 64, 56, 56]       6,422,528               0          0          0          0\n",
      "                   ReLU-3  [32, 64, 112, 112]               0               0 25,690,112          0          0\n",
      "            BatchNorm2d-2  [32, 64, 112, 112]     205,520,640     179,831,296          0          0          0\n",
      "                 Conv2d-1  [32, 64, 112, 112]   7,547,774,976   7,552,892,928          0          0          0\n",
      "======================================================================================================\n",
      "Total FLOPs: 233,031,103,232\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.59\n",
      "Backward pass size (MB): 456.40\n",
      "FLOPs size (GB): 233.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net = models.resnet18()\n",
    "scope(net, input_size=(3, 224, 224), batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8e6c369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tensor name data is changed to t_data.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm0_gamma is changed to t_resnetv22_batchnorm0_gamma.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm0_beta is changed to t_resnetv22_batchnorm0_beta.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm0_running_mean is changed to t_resnetv22_batchnorm0_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm0_running_var is changed to t_resnetv22_batchnorm0_running_var.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm0_fwd is changed to t_resnetv22_batchnorm0_fwd.\n",
      "WARNING:root:Node name resnetv22_batchnorm0_fwd is changed to n_resnetv22_batchnorm0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm0_fwd is changed to t_resnetv22_batchnorm0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_conv0_weight is changed to t_resnetv22_conv0_weight.\n",
      "WARNING:root:Tensor name resnetv22_conv0_fwd is changed to t_resnetv22_conv0_fwd.\n",
      "WARNING:root:Node name resnetv22_conv0_fwd is changed to n_resnetv22_conv0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_conv0_fwd is changed to t_resnetv22_conv0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm1_gamma is changed to t_resnetv22_batchnorm1_gamma.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm1_beta is changed to t_resnetv22_batchnorm1_beta.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm1_running_mean is changed to t_resnetv22_batchnorm1_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm1_running_var is changed to t_resnetv22_batchnorm1_running_var.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm1_fwd is changed to t_resnetv22_batchnorm1_fwd.\n",
      "WARNING:root:Node name resnetv22_batchnorm1_fwd is changed to n_resnetv22_batchnorm1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm1_fwd is changed to t_resnetv22_batchnorm1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_relu0_fwd is changed to t_resnetv22_relu0_fwd.\n",
      "WARNING:root:Node name resnetv22_relu0_fwd is changed to n_resnetv22_relu0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_relu0_fwd is changed to t_resnetv22_relu0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_pool0_fwd is changed to t_resnetv22_pool0_fwd.\n",
      "WARNING:root:Node name resnetv22_pool0_fwd is changed to n_resnetv22_pool0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_pool0_fwd is changed to t_resnetv22_pool0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm0_gamma is changed to t_resnetv22_stage1_batchnorm0_gamma.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm0_beta is changed to t_resnetv22_stage1_batchnorm0_beta.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm0_running_mean is changed to t_resnetv22_stage1_batchnorm0_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm0_running_var is changed to t_resnetv22_stage1_batchnorm0_running_var.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm0_fwd is changed to t_resnetv22_stage1_batchnorm0_fwd.\n",
      "WARNING:root:Node name resnetv22_stage1_batchnorm0_fwd is changed to n_resnetv22_stage1_batchnorm0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm0_fwd is changed to t_resnetv22_stage1_batchnorm0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage1_activation0 is changed to t_resnetv22_stage1_activation0.\n",
      "WARNING:root:Node name resnetv22_stage1_activation0 is changed to n_resnetv22_stage1_activation0.\n",
      "WARNING:root:Tensor name resnetv22_stage1_activation0 is changed to t_resnetv22_stage1_activation0.\n",
      "WARNING:root:Tensor name resnetv22_stage1_conv0_weight is changed to t_resnetv22_stage1_conv0_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage1_conv0_fwd is changed to t_resnetv22_stage1_conv0_fwd.\n",
      "WARNING:root:Node name resnetv22_stage1_conv0_fwd is changed to n_resnetv22_stage1_conv0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage1_conv0_fwd is changed to t_resnetv22_stage1_conv0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm1_gamma is changed to t_resnetv22_stage1_batchnorm1_gamma.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm1_beta is changed to t_resnetv22_stage1_batchnorm1_beta.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm1_running_mean is changed to t_resnetv22_stage1_batchnorm1_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm1_running_var is changed to t_resnetv22_stage1_batchnorm1_running_var.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm1_fwd is changed to t_resnetv22_stage1_batchnorm1_fwd.\n",
      "WARNING:root:Node name resnetv22_stage1_batchnorm1_fwd is changed to n_resnetv22_stage1_batchnorm1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm1_fwd is changed to t_resnetv22_stage1_batchnorm1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage1_activation1 is changed to t_resnetv22_stage1_activation1.\n",
      "WARNING:root:Node name resnetv22_stage1_activation1 is changed to n_resnetv22_stage1_activation1.\n",
      "WARNING:root:Tensor name resnetv22_stage1_activation1 is changed to t_resnetv22_stage1_activation1.\n",
      "WARNING:root:Tensor name resnetv22_stage1_conv1_weight is changed to t_resnetv22_stage1_conv1_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage1_conv1_fwd is changed to t_resnetv22_stage1_conv1_fwd.\n",
      "WARNING:root:Node name resnetv22_stage1_conv1_fwd is changed to n_resnetv22_stage1_conv1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage1_conv1_fwd is changed to t_resnetv22_stage1_conv1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_pool0_fwd is changed to t_resnetv22_pool0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage1__plus0 is changed to t_resnetv22_stage1__plus0.\n",
      "WARNING:root:Node name resnetv22_stage1__plus0 is changed to n_resnetv22_stage1__plus0.\n",
      "WARNING:root:Tensor name resnetv22_stage1__plus0 is changed to t_resnetv22_stage1__plus0.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm2_gamma is changed to t_resnetv22_stage1_batchnorm2_gamma.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm2_beta is changed to t_resnetv22_stage1_batchnorm2_beta.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm2_running_mean is changed to t_resnetv22_stage1_batchnorm2_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm2_running_var is changed to t_resnetv22_stage1_batchnorm2_running_var.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm2_fwd is changed to t_resnetv22_stage1_batchnorm2_fwd.\n",
      "WARNING:root:Node name resnetv22_stage1_batchnorm2_fwd is changed to n_resnetv22_stage1_batchnorm2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm2_fwd is changed to t_resnetv22_stage1_batchnorm2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage1_activation2 is changed to t_resnetv22_stage1_activation2.\n",
      "WARNING:root:Node name resnetv22_stage1_activation2 is changed to n_resnetv22_stage1_activation2.\n",
      "WARNING:root:Tensor name resnetv22_stage1_activation2 is changed to t_resnetv22_stage1_activation2.\n",
      "WARNING:root:Tensor name resnetv22_stage1_conv2_weight is changed to t_resnetv22_stage1_conv2_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage1_conv2_fwd is changed to t_resnetv22_stage1_conv2_fwd.\n",
      "WARNING:root:Node name resnetv22_stage1_conv2_fwd is changed to n_resnetv22_stage1_conv2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage1_conv2_fwd is changed to t_resnetv22_stage1_conv2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm3_gamma is changed to t_resnetv22_stage1_batchnorm3_gamma.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm3_beta is changed to t_resnetv22_stage1_batchnorm3_beta.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm3_running_mean is changed to t_resnetv22_stage1_batchnorm3_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm3_running_var is changed to t_resnetv22_stage1_batchnorm3_running_var.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm3_fwd is changed to t_resnetv22_stage1_batchnorm3_fwd.\n",
      "WARNING:root:Node name resnetv22_stage1_batchnorm3_fwd is changed to n_resnetv22_stage1_batchnorm3_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage1_batchnorm3_fwd is changed to t_resnetv22_stage1_batchnorm3_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage1_activation3 is changed to t_resnetv22_stage1_activation3.\n",
      "WARNING:root:Node name resnetv22_stage1_activation3 is changed to n_resnetv22_stage1_activation3.\n",
      "WARNING:root:Tensor name resnetv22_stage1_activation3 is changed to t_resnetv22_stage1_activation3.\n",
      "WARNING:root:Tensor name resnetv22_stage1_conv3_weight is changed to t_resnetv22_stage1_conv3_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage1_conv3_fwd is changed to t_resnetv22_stage1_conv3_fwd.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Node name resnetv22_stage1_conv3_fwd is changed to n_resnetv22_stage1_conv3_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage1_conv3_fwd is changed to t_resnetv22_stage1_conv3_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage1__plus0 is changed to t_resnetv22_stage1__plus0.\n",
      "WARNING:root:Tensor name resnetv22_stage1__plus1 is changed to t_resnetv22_stage1__plus1.\n",
      "WARNING:root:Node name resnetv22_stage1__plus1 is changed to n_resnetv22_stage1__plus1.\n",
      "WARNING:root:Tensor name resnetv22_stage1__plus1 is changed to t_resnetv22_stage1__plus1.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm0_gamma is changed to t_resnetv22_stage2_batchnorm0_gamma.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm0_beta is changed to t_resnetv22_stage2_batchnorm0_beta.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm0_running_mean is changed to t_resnetv22_stage2_batchnorm0_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm0_running_var is changed to t_resnetv22_stage2_batchnorm0_running_var.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm0_fwd is changed to t_resnetv22_stage2_batchnorm0_fwd.\n",
      "WARNING:root:Node name resnetv22_stage2_batchnorm0_fwd is changed to n_resnetv22_stage2_batchnorm0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm0_fwd is changed to t_resnetv22_stage2_batchnorm0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2_activation0 is changed to t_resnetv22_stage2_activation0.\n",
      "WARNING:root:Node name resnetv22_stage2_activation0 is changed to n_resnetv22_stage2_activation0.\n",
      "WARNING:root:Tensor name resnetv22_stage2_activation0 is changed to t_resnetv22_stage2_activation0.\n",
      "WARNING:root:Tensor name resnetv22_stage2_conv0_weight is changed to t_resnetv22_stage2_conv0_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage2_conv0_fwd is changed to t_resnetv22_stage2_conv0_fwd.\n",
      "WARNING:root:Node name resnetv22_stage2_conv0_fwd is changed to n_resnetv22_stage2_conv0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2_conv0_fwd is changed to t_resnetv22_stage2_conv0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm1_gamma is changed to t_resnetv22_stage2_batchnorm1_gamma.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm1_beta is changed to t_resnetv22_stage2_batchnorm1_beta.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm1_running_mean is changed to t_resnetv22_stage2_batchnorm1_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm1_running_var is changed to t_resnetv22_stage2_batchnorm1_running_var.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm1_fwd is changed to t_resnetv22_stage2_batchnorm1_fwd.\n",
      "WARNING:root:Node name resnetv22_stage2_batchnorm1_fwd is changed to n_resnetv22_stage2_batchnorm1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm1_fwd is changed to t_resnetv22_stage2_batchnorm1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2_activation1 is changed to t_resnetv22_stage2_activation1.\n",
      "WARNING:root:Node name resnetv22_stage2_activation1 is changed to n_resnetv22_stage2_activation1.\n",
      "WARNING:root:Tensor name resnetv22_stage2_activation1 is changed to t_resnetv22_stage2_activation1.\n",
      "WARNING:root:Tensor name resnetv22_stage2_conv1_weight is changed to t_resnetv22_stage2_conv1_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage2_conv1_fwd is changed to t_resnetv22_stage2_conv1_fwd.\n",
      "WARNING:root:Node name resnetv22_stage2_conv1_fwd is changed to n_resnetv22_stage2_conv1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2_activation0 is changed to t_resnetv22_stage2_activation0.\n",
      "WARNING:root:Tensor name resnetv22_stage2_conv2_weight is changed to t_resnetv22_stage2_conv2_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage2_conv2_fwd is changed to t_resnetv22_stage2_conv2_fwd.\n",
      "WARNING:root:Node name resnetv22_stage2_conv2_fwd is changed to n_resnetv22_stage2_conv2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2_conv1_fwd is changed to t_resnetv22_stage2_conv1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2_conv2_fwd is changed to t_resnetv22_stage2_conv2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2__plus0 is changed to t_resnetv22_stage2__plus0.\n",
      "WARNING:root:Node name resnetv22_stage2__plus0 is changed to n_resnetv22_stage2__plus0.\n",
      "WARNING:root:Tensor name resnetv22_stage2__plus0 is changed to t_resnetv22_stage2__plus0.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm2_gamma is changed to t_resnetv22_stage2_batchnorm2_gamma.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm2_beta is changed to t_resnetv22_stage2_batchnorm2_beta.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm2_running_mean is changed to t_resnetv22_stage2_batchnorm2_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm2_running_var is changed to t_resnetv22_stage2_batchnorm2_running_var.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm2_fwd is changed to t_resnetv22_stage2_batchnorm2_fwd.\n",
      "WARNING:root:Node name resnetv22_stage2_batchnorm2_fwd is changed to n_resnetv22_stage2_batchnorm2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm2_fwd is changed to t_resnetv22_stage2_batchnorm2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2_activation2 is changed to t_resnetv22_stage2_activation2.\n",
      "WARNING:root:Node name resnetv22_stage2_activation2 is changed to n_resnetv22_stage2_activation2.\n",
      "WARNING:root:Tensor name resnetv22_stage2_activation2 is changed to t_resnetv22_stage2_activation2.\n",
      "WARNING:root:Tensor name resnetv22_stage2_conv3_weight is changed to t_resnetv22_stage2_conv3_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage2_conv3_fwd is changed to t_resnetv22_stage2_conv3_fwd.\n",
      "WARNING:root:Node name resnetv22_stage2_conv3_fwd is changed to n_resnetv22_stage2_conv3_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2_conv3_fwd is changed to t_resnetv22_stage2_conv3_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm3_gamma is changed to t_resnetv22_stage2_batchnorm3_gamma.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm3_beta is changed to t_resnetv22_stage2_batchnorm3_beta.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm3_running_mean is changed to t_resnetv22_stage2_batchnorm3_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm3_running_var is changed to t_resnetv22_stage2_batchnorm3_running_var.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm3_fwd is changed to t_resnetv22_stage2_batchnorm3_fwd.\n",
      "WARNING:root:Node name resnetv22_stage2_batchnorm3_fwd is changed to n_resnetv22_stage2_batchnorm3_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2_batchnorm3_fwd is changed to t_resnetv22_stage2_batchnorm3_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2_activation3 is changed to t_resnetv22_stage2_activation3.\n",
      "WARNING:root:Node name resnetv22_stage2_activation3 is changed to n_resnetv22_stage2_activation3.\n",
      "WARNING:root:Tensor name resnetv22_stage2_activation3 is changed to t_resnetv22_stage2_activation3.\n",
      "WARNING:root:Tensor name resnetv22_stage2_conv4_weight is changed to t_resnetv22_stage2_conv4_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage2_conv4_fwd is changed to t_resnetv22_stage2_conv4_fwd.\n",
      "WARNING:root:Node name resnetv22_stage2_conv4_fwd is changed to n_resnetv22_stage2_conv4_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2_conv4_fwd is changed to t_resnetv22_stage2_conv4_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage2__plus0 is changed to t_resnetv22_stage2__plus0.\n",
      "WARNING:root:Tensor name resnetv22_stage2__plus1 is changed to t_resnetv22_stage2__plus1.\n",
      "WARNING:root:Node name resnetv22_stage2__plus1 is changed to n_resnetv22_stage2__plus1.\n",
      "WARNING:root:Tensor name resnetv22_stage2__plus1 is changed to t_resnetv22_stage2__plus1.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm0_gamma is changed to t_resnetv22_stage3_batchnorm0_gamma.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm0_beta is changed to t_resnetv22_stage3_batchnorm0_beta.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm0_running_mean is changed to t_resnetv22_stage3_batchnorm0_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm0_running_var is changed to t_resnetv22_stage3_batchnorm0_running_var.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm0_fwd is changed to t_resnetv22_stage3_batchnorm0_fwd.\n",
      "WARNING:root:Node name resnetv22_stage3_batchnorm0_fwd is changed to n_resnetv22_stage3_batchnorm0_fwd.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm0_fwd is changed to t_resnetv22_stage3_batchnorm0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage3_activation0 is changed to t_resnetv22_stage3_activation0.\n",
      "WARNING:root:Node name resnetv22_stage3_activation0 is changed to n_resnetv22_stage3_activation0.\n",
      "WARNING:root:Tensor name resnetv22_stage3_activation0 is changed to t_resnetv22_stage3_activation0.\n",
      "WARNING:root:Tensor name resnetv22_stage3_conv0_weight is changed to t_resnetv22_stage3_conv0_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage3_conv0_fwd is changed to t_resnetv22_stage3_conv0_fwd.\n",
      "WARNING:root:Node name resnetv22_stage3_conv0_fwd is changed to n_resnetv22_stage3_conv0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage3_conv0_fwd is changed to t_resnetv22_stage3_conv0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm1_gamma is changed to t_resnetv22_stage3_batchnorm1_gamma.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm1_beta is changed to t_resnetv22_stage3_batchnorm1_beta.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm1_running_mean is changed to t_resnetv22_stage3_batchnorm1_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm1_running_var is changed to t_resnetv22_stage3_batchnorm1_running_var.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm1_fwd is changed to t_resnetv22_stage3_batchnorm1_fwd.\n",
      "WARNING:root:Node name resnetv22_stage3_batchnorm1_fwd is changed to n_resnetv22_stage3_batchnorm1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm1_fwd is changed to t_resnetv22_stage3_batchnorm1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage3_activation1 is changed to t_resnetv22_stage3_activation1.\n",
      "WARNING:root:Node name resnetv22_stage3_activation1 is changed to n_resnetv22_stage3_activation1.\n",
      "WARNING:root:Tensor name resnetv22_stage3_activation1 is changed to t_resnetv22_stage3_activation1.\n",
      "WARNING:root:Tensor name resnetv22_stage3_conv1_weight is changed to t_resnetv22_stage3_conv1_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage3_conv1_fwd is changed to t_resnetv22_stage3_conv1_fwd.\n",
      "WARNING:root:Node name resnetv22_stage3_conv1_fwd is changed to n_resnetv22_stage3_conv1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage3_activation0 is changed to t_resnetv22_stage3_activation0.\n",
      "WARNING:root:Tensor name resnetv22_stage3_conv2_weight is changed to t_resnetv22_stage3_conv2_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage3_conv2_fwd is changed to t_resnetv22_stage3_conv2_fwd.\n",
      "WARNING:root:Node name resnetv22_stage3_conv2_fwd is changed to n_resnetv22_stage3_conv2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage3_conv1_fwd is changed to t_resnetv22_stage3_conv1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage3_conv2_fwd is changed to t_resnetv22_stage3_conv2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage3__plus0 is changed to t_resnetv22_stage3__plus0.\n",
      "WARNING:root:Node name resnetv22_stage3__plus0 is changed to n_resnetv22_stage3__plus0.\n",
      "WARNING:root:Tensor name resnetv22_stage3__plus0 is changed to t_resnetv22_stage3__plus0.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm2_gamma is changed to t_resnetv22_stage3_batchnorm2_gamma.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm2_beta is changed to t_resnetv22_stage3_batchnorm2_beta.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm2_running_mean is changed to t_resnetv22_stage3_batchnorm2_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm2_running_var is changed to t_resnetv22_stage3_batchnorm2_running_var.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm2_fwd is changed to t_resnetv22_stage3_batchnorm2_fwd.\n",
      "WARNING:root:Node name resnetv22_stage3_batchnorm2_fwd is changed to n_resnetv22_stage3_batchnorm2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm2_fwd is changed to t_resnetv22_stage3_batchnorm2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage3_activation2 is changed to t_resnetv22_stage3_activation2.\n",
      "WARNING:root:Node name resnetv22_stage3_activation2 is changed to n_resnetv22_stage3_activation2.\n",
      "WARNING:root:Tensor name resnetv22_stage3_activation2 is changed to t_resnetv22_stage3_activation2.\n",
      "WARNING:root:Tensor name resnetv22_stage3_conv3_weight is changed to t_resnetv22_stage3_conv3_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage3_conv3_fwd is changed to t_resnetv22_stage3_conv3_fwd.\n",
      "WARNING:root:Node name resnetv22_stage3_conv3_fwd is changed to n_resnetv22_stage3_conv3_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage3_conv3_fwd is changed to t_resnetv22_stage3_conv3_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm3_gamma is changed to t_resnetv22_stage3_batchnorm3_gamma.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm3_beta is changed to t_resnetv22_stage3_batchnorm3_beta.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm3_running_mean is changed to t_resnetv22_stage3_batchnorm3_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm3_running_var is changed to t_resnetv22_stage3_batchnorm3_running_var.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm3_fwd is changed to t_resnetv22_stage3_batchnorm3_fwd.\n",
      "WARNING:root:Node name resnetv22_stage3_batchnorm3_fwd is changed to n_resnetv22_stage3_batchnorm3_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage3_batchnorm3_fwd is changed to t_resnetv22_stage3_batchnorm3_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage3_activation3 is changed to t_resnetv22_stage3_activation3.\n",
      "WARNING:root:Node name resnetv22_stage3_activation3 is changed to n_resnetv22_stage3_activation3.\n",
      "WARNING:root:Tensor name resnetv22_stage3_activation3 is changed to t_resnetv22_stage3_activation3.\n",
      "WARNING:root:Tensor name resnetv22_stage3_conv4_weight is changed to t_resnetv22_stage3_conv4_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage3_conv4_fwd is changed to t_resnetv22_stage3_conv4_fwd.\n",
      "WARNING:root:Node name resnetv22_stage3_conv4_fwd is changed to n_resnetv22_stage3_conv4_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage3_conv4_fwd is changed to t_resnetv22_stage3_conv4_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage3__plus0 is changed to t_resnetv22_stage3__plus0.\n",
      "WARNING:root:Tensor name resnetv22_stage3__plus1 is changed to t_resnetv22_stage3__plus1.\n",
      "WARNING:root:Node name resnetv22_stage3__plus1 is changed to n_resnetv22_stage3__plus1.\n",
      "WARNING:root:Tensor name resnetv22_stage3__plus1 is changed to t_resnetv22_stage3__plus1.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm0_gamma is changed to t_resnetv22_stage4_batchnorm0_gamma.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm0_beta is changed to t_resnetv22_stage4_batchnorm0_beta.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm0_running_mean is changed to t_resnetv22_stage4_batchnorm0_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm0_running_var is changed to t_resnetv22_stage4_batchnorm0_running_var.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm0_fwd is changed to t_resnetv22_stage4_batchnorm0_fwd.\n",
      "WARNING:root:Node name resnetv22_stage4_batchnorm0_fwd is changed to n_resnetv22_stage4_batchnorm0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm0_fwd is changed to t_resnetv22_stage4_batchnorm0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4_activation0 is changed to t_resnetv22_stage4_activation0.\n",
      "WARNING:root:Node name resnetv22_stage4_activation0 is changed to n_resnetv22_stage4_activation0.\n",
      "WARNING:root:Tensor name resnetv22_stage4_activation0 is changed to t_resnetv22_stage4_activation0.\n",
      "WARNING:root:Tensor name resnetv22_stage4_conv0_weight is changed to t_resnetv22_stage4_conv0_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage4_conv0_fwd is changed to t_resnetv22_stage4_conv0_fwd.\n",
      "WARNING:root:Node name resnetv22_stage4_conv0_fwd is changed to n_resnetv22_stage4_conv0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4_conv0_fwd is changed to t_resnetv22_stage4_conv0_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm1_gamma is changed to t_resnetv22_stage4_batchnorm1_gamma.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm1_beta is changed to t_resnetv22_stage4_batchnorm1_beta.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm1_running_mean is changed to t_resnetv22_stage4_batchnorm1_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm1_running_var is changed to t_resnetv22_stage4_batchnorm1_running_var.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm1_fwd is changed to t_resnetv22_stage4_batchnorm1_fwd.\n",
      "WARNING:root:Node name resnetv22_stage4_batchnorm1_fwd is changed to n_resnetv22_stage4_batchnorm1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm1_fwd is changed to t_resnetv22_stage4_batchnorm1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4_activation1 is changed to t_resnetv22_stage4_activation1.\n",
      "WARNING:root:Node name resnetv22_stage4_activation1 is changed to n_resnetv22_stage4_activation1.\n",
      "WARNING:root:Tensor name resnetv22_stage4_activation1 is changed to t_resnetv22_stage4_activation1.\n",
      "WARNING:root:Tensor name resnetv22_stage4_conv1_weight is changed to t_resnetv22_stage4_conv1_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage4_conv1_fwd is changed to t_resnetv22_stage4_conv1_fwd.\n",
      "WARNING:root:Node name resnetv22_stage4_conv1_fwd is changed to n_resnetv22_stage4_conv1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4_activation0 is changed to t_resnetv22_stage4_activation0.\n",
      "WARNING:root:Tensor name resnetv22_stage4_conv2_weight is changed to t_resnetv22_stage4_conv2_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage4_conv2_fwd is changed to t_resnetv22_stage4_conv2_fwd.\n",
      "WARNING:root:Node name resnetv22_stage4_conv2_fwd is changed to n_resnetv22_stage4_conv2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4_conv1_fwd is changed to t_resnetv22_stage4_conv1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4_conv2_fwd is changed to t_resnetv22_stage4_conv2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4__plus0 is changed to t_resnetv22_stage4__plus0.\n",
      "WARNING:root:Node name resnetv22_stage4__plus0 is changed to n_resnetv22_stage4__plus0.\n",
      "WARNING:root:Tensor name resnetv22_stage4__plus0 is changed to t_resnetv22_stage4__plus0.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm2_gamma is changed to t_resnetv22_stage4_batchnorm2_gamma.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm2_beta is changed to t_resnetv22_stage4_batchnorm2_beta.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm2_running_mean is changed to t_resnetv22_stage4_batchnorm2_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm2_running_var is changed to t_resnetv22_stage4_batchnorm2_running_var.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm2_fwd is changed to t_resnetv22_stage4_batchnorm2_fwd.\n",
      "WARNING:root:Node name resnetv22_stage4_batchnorm2_fwd is changed to n_resnetv22_stage4_batchnorm2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm2_fwd is changed to t_resnetv22_stage4_batchnorm2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4_activation2 is changed to t_resnetv22_stage4_activation2.\n",
      "WARNING:root:Node name resnetv22_stage4_activation2 is changed to n_resnetv22_stage4_activation2.\n",
      "WARNING:root:Tensor name resnetv22_stage4_activation2 is changed to t_resnetv22_stage4_activation2.\n",
      "WARNING:root:Tensor name resnetv22_stage4_conv3_weight is changed to t_resnetv22_stage4_conv3_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage4_conv3_fwd is changed to t_resnetv22_stage4_conv3_fwd.\n",
      "WARNING:root:Node name resnetv22_stage4_conv3_fwd is changed to n_resnetv22_stage4_conv3_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4_conv3_fwd is changed to t_resnetv22_stage4_conv3_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm3_gamma is changed to t_resnetv22_stage4_batchnorm3_gamma.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm3_beta is changed to t_resnetv22_stage4_batchnorm3_beta.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm3_running_mean is changed to t_resnetv22_stage4_batchnorm3_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm3_running_var is changed to t_resnetv22_stage4_batchnorm3_running_var.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm3_fwd is changed to t_resnetv22_stage4_batchnorm3_fwd.\n",
      "WARNING:root:Node name resnetv22_stage4_batchnorm3_fwd is changed to n_resnetv22_stage4_batchnorm3_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4_batchnorm3_fwd is changed to t_resnetv22_stage4_batchnorm3_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4_activation3 is changed to t_resnetv22_stage4_activation3.\n",
      "WARNING:root:Node name resnetv22_stage4_activation3 is changed to n_resnetv22_stage4_activation3.\n",
      "WARNING:root:Tensor name resnetv22_stage4_activation3 is changed to t_resnetv22_stage4_activation3.\n",
      "WARNING:root:Tensor name resnetv22_stage4_conv4_weight is changed to t_resnetv22_stage4_conv4_weight.\n",
      "WARNING:root:Tensor name resnetv22_stage4_conv4_fwd is changed to t_resnetv22_stage4_conv4_fwd.\n",
      "WARNING:root:Node name resnetv22_stage4_conv4_fwd is changed to n_resnetv22_stage4_conv4_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4_conv4_fwd is changed to t_resnetv22_stage4_conv4_fwd.\n",
      "WARNING:root:Tensor name resnetv22_stage4__plus0 is changed to t_resnetv22_stage4__plus0.\n",
      "WARNING:root:Tensor name resnetv22_stage4__plus1 is changed to t_resnetv22_stage4__plus1.\n",
      "WARNING:root:Node name resnetv22_stage4__plus1 is changed to n_resnetv22_stage4__plus1.\n",
      "WARNING:root:Tensor name resnetv22_stage4__plus1 is changed to t_resnetv22_stage4__plus1.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm2_gamma is changed to t_resnetv22_batchnorm2_gamma.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm2_beta is changed to t_resnetv22_batchnorm2_beta.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm2_running_mean is changed to t_resnetv22_batchnorm2_running_mean.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm2_running_var is changed to t_resnetv22_batchnorm2_running_var.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm2_fwd is changed to t_resnetv22_batchnorm2_fwd.\n",
      "WARNING:root:Node name resnetv22_batchnorm2_fwd is changed to n_resnetv22_batchnorm2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_batchnorm2_fwd is changed to t_resnetv22_batchnorm2_fwd.\n",
      "WARNING:root:Tensor name resnetv22_relu1_fwd is changed to t_resnetv22_relu1_fwd.\n",
      "WARNING:root:Node name resnetv22_relu1_fwd is changed to n_resnetv22_relu1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_relu1_fwd is changed to t_resnetv22_relu1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_pool1_fwd is changed to t_resnetv22_pool1_fwd.\n",
      "WARNING:root:Node name resnetv22_pool1_fwd is changed to n_resnetv22_pool1_fwd.\n",
      "WARNING:root:Tensor name resnetv22_pool1_fwd is changed to t_resnetv22_pool1_fwd.\n",
      "WARNING:root:Tensor name reshape_attr_tensor164 is changed to t_reshape_attr_tensor164.\n",
      "WARNING:root:Tensor name resnetv22_flatten0_reshape0 is changed to t_resnetv22_flatten0_reshape0.\n",
      "WARNING:root:Node name resnetv22_flatten0_reshape0 is changed to n_resnetv22_flatten0_reshape0.\n",
      "WARNING:root:Tensor name resnetv22_flatten0_reshape0 is changed to t_resnetv22_flatten0_reshape0.\n",
      "WARNING:root:Tensor name resnetv22_dense0_weight is changed to t_resnetv22_dense0_weight.\n",
      "WARNING:root:Tensor name resnetv22_dense0_bias is changed to t_resnetv22_dense0_bias.\n",
      "WARNING:root:Tensor name resnetv22_dense0_fwd is changed to t_resnetv22_dense0_fwd.\n",
      "WARNING:root:Node name resnetv22_dense0_fwd is changed to n_resnetv22_dense0_fwd.\n",
      "WARNING:root:Tensor name t_data is changed to t_data.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm0_gamma is changed to t_resnetv22_batchnorm0_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm0_beta is changed to t_resnetv22_batchnorm0_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm0_running_mean is changed to t_resnetv22_batchnorm0_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm0_running_var is changed to t_resnetv22_batchnorm0_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_conv0_weight is changed to t_resnetv22_conv0_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm1_gamma is changed to t_resnetv22_batchnorm1_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm1_beta is changed to t_resnetv22_batchnorm1_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm1_running_mean is changed to t_resnetv22_batchnorm1_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm1_running_var is changed to t_resnetv22_batchnorm1_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm0_gamma is changed to t_resnetv22_stage1_batchnorm0_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm0_beta is changed to t_resnetv22_stage1_batchnorm0_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm0_running_mean is changed to t_resnetv22_stage1_batchnorm0_running_mean.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm0_running_var is changed to t_resnetv22_stage1_batchnorm0_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_conv0_weight is changed to t_resnetv22_stage1_conv0_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm1_gamma is changed to t_resnetv22_stage1_batchnorm1_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm1_beta is changed to t_resnetv22_stage1_batchnorm1_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm1_running_mean is changed to t_resnetv22_stage1_batchnorm1_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm1_running_var is changed to t_resnetv22_stage1_batchnorm1_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_conv1_weight is changed to t_resnetv22_stage1_conv1_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm2_gamma is changed to t_resnetv22_stage1_batchnorm2_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm2_beta is changed to t_resnetv22_stage1_batchnorm2_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm2_running_mean is changed to t_resnetv22_stage1_batchnorm2_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm2_running_var is changed to t_resnetv22_stage1_batchnorm2_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_conv2_weight is changed to t_resnetv22_stage1_conv2_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm3_gamma is changed to t_resnetv22_stage1_batchnorm3_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm3_beta is changed to t_resnetv22_stage1_batchnorm3_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm3_running_mean is changed to t_resnetv22_stage1_batchnorm3_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm3_running_var is changed to t_resnetv22_stage1_batchnorm3_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_conv3_weight is changed to t_resnetv22_stage1_conv3_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm0_gamma is changed to t_resnetv22_stage2_batchnorm0_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm0_beta is changed to t_resnetv22_stage2_batchnorm0_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm0_running_mean is changed to t_resnetv22_stage2_batchnorm0_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm0_running_var is changed to t_resnetv22_stage2_batchnorm0_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_conv0_weight is changed to t_resnetv22_stage2_conv0_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm1_gamma is changed to t_resnetv22_stage2_batchnorm1_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm1_beta is changed to t_resnetv22_stage2_batchnorm1_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm1_running_mean is changed to t_resnetv22_stage2_batchnorm1_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm1_running_var is changed to t_resnetv22_stage2_batchnorm1_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_conv1_weight is changed to t_resnetv22_stage2_conv1_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_conv2_weight is changed to t_resnetv22_stage2_conv2_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm2_gamma is changed to t_resnetv22_stage2_batchnorm2_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm2_beta is changed to t_resnetv22_stage2_batchnorm2_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm2_running_mean is changed to t_resnetv22_stage2_batchnorm2_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm2_running_var is changed to t_resnetv22_stage2_batchnorm2_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_conv3_weight is changed to t_resnetv22_stage2_conv3_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm3_gamma is changed to t_resnetv22_stage2_batchnorm3_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm3_beta is changed to t_resnetv22_stage2_batchnorm3_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm3_running_mean is changed to t_resnetv22_stage2_batchnorm3_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm3_running_var is changed to t_resnetv22_stage2_batchnorm3_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_conv4_weight is changed to t_resnetv22_stage2_conv4_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm0_gamma is changed to t_resnetv22_stage3_batchnorm0_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm0_beta is changed to t_resnetv22_stage3_batchnorm0_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm0_running_mean is changed to t_resnetv22_stage3_batchnorm0_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm0_running_var is changed to t_resnetv22_stage3_batchnorm0_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_conv0_weight is changed to t_resnetv22_stage3_conv0_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm1_gamma is changed to t_resnetv22_stage3_batchnorm1_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm1_beta is changed to t_resnetv22_stage3_batchnorm1_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm1_running_mean is changed to t_resnetv22_stage3_batchnorm1_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm1_running_var is changed to t_resnetv22_stage3_batchnorm1_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_conv1_weight is changed to t_resnetv22_stage3_conv1_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_conv2_weight is changed to t_resnetv22_stage3_conv2_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm2_gamma is changed to t_resnetv22_stage3_batchnorm2_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm2_beta is changed to t_resnetv22_stage3_batchnorm2_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm2_running_mean is changed to t_resnetv22_stage3_batchnorm2_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm2_running_var is changed to t_resnetv22_stage3_batchnorm2_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_conv3_weight is changed to t_resnetv22_stage3_conv3_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm3_gamma is changed to t_resnetv22_stage3_batchnorm3_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm3_beta is changed to t_resnetv22_stage3_batchnorm3_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm3_running_mean is changed to t_resnetv22_stage3_batchnorm3_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm3_running_var is changed to t_resnetv22_stage3_batchnorm3_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_conv4_weight is changed to t_resnetv22_stage3_conv4_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm0_gamma is changed to t_resnetv22_stage4_batchnorm0_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm0_beta is changed to t_resnetv22_stage4_batchnorm0_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm0_running_mean is changed to t_resnetv22_stage4_batchnorm0_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm0_running_var is changed to t_resnetv22_stage4_batchnorm0_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_conv0_weight is changed to t_resnetv22_stage4_conv0_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm1_gamma is changed to t_resnetv22_stage4_batchnorm1_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm1_beta is changed to t_resnetv22_stage4_batchnorm1_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm1_running_mean is changed to t_resnetv22_stage4_batchnorm1_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm1_running_var is changed to t_resnetv22_stage4_batchnorm1_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_conv1_weight is changed to t_resnetv22_stage4_conv1_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_conv2_weight is changed to t_resnetv22_stage4_conv2_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm2_gamma is changed to t_resnetv22_stage4_batchnorm2_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm2_beta is changed to t_resnetv22_stage4_batchnorm2_beta.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm2_running_mean is changed to t_resnetv22_stage4_batchnorm2_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm2_running_var is changed to t_resnetv22_stage4_batchnorm2_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_conv3_weight is changed to t_resnetv22_stage4_conv3_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm3_gamma is changed to t_resnetv22_stage4_batchnorm3_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm3_beta is changed to t_resnetv22_stage4_batchnorm3_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm3_running_mean is changed to t_resnetv22_stage4_batchnorm3_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm3_running_var is changed to t_resnetv22_stage4_batchnorm3_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_conv4_weight is changed to t_resnetv22_stage4_conv4_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm2_gamma is changed to t_resnetv22_batchnorm2_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm2_beta is changed to t_resnetv22_batchnorm2_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm2_running_mean is changed to t_resnetv22_batchnorm2_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm2_running_var is changed to t_resnetv22_batchnorm2_running_var.\n",
      "WARNING:root:Tensor name t_reshape_attr_tensor164 is changed to t_reshape_attr_tensor164.\n",
      "WARNING:root:Tensor name t_resnetv22_dense0_weight is changed to t_resnetv22_dense0_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_dense0_bias is changed to t_resnetv22_dense0_bias.\n",
      "WARNING:root:Tensor name t_resnetv22_dense0_fwd is changed to t_resnetv22_dense0_fwd.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm0_gamma is changed to t_resnetv22_batchnorm0_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm0_beta is changed to t_resnetv22_batchnorm0_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm0_running_mean is changed to t_resnetv22_batchnorm0_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm0_running_var is changed to t_resnetv22_batchnorm0_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_conv0_weight is changed to t_resnetv22_conv0_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm1_gamma is changed to t_resnetv22_batchnorm1_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm1_beta is changed to t_resnetv22_batchnorm1_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm1_running_mean is changed to t_resnetv22_batchnorm1_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm1_running_var is changed to t_resnetv22_batchnorm1_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm0_gamma is changed to t_resnetv22_stage1_batchnorm0_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm0_beta is changed to t_resnetv22_stage1_batchnorm0_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm0_running_mean is changed to t_resnetv22_stage1_batchnorm0_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm0_running_var is changed to t_resnetv22_stage1_batchnorm0_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_conv0_weight is changed to t_resnetv22_stage1_conv0_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm1_gamma is changed to t_resnetv22_stage1_batchnorm1_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm1_beta is changed to t_resnetv22_stage1_batchnorm1_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm1_running_mean is changed to t_resnetv22_stage1_batchnorm1_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm1_running_var is changed to t_resnetv22_stage1_batchnorm1_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_conv1_weight is changed to t_resnetv22_stage1_conv1_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm2_gamma is changed to t_resnetv22_stage1_batchnorm2_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm2_beta is changed to t_resnetv22_stage1_batchnorm2_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm2_running_mean is changed to t_resnetv22_stage1_batchnorm2_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm2_running_var is changed to t_resnetv22_stage1_batchnorm2_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_conv2_weight is changed to t_resnetv22_stage1_conv2_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm3_gamma is changed to t_resnetv22_stage1_batchnorm3_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm3_beta is changed to t_resnetv22_stage1_batchnorm3_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm3_running_mean is changed to t_resnetv22_stage1_batchnorm3_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_batchnorm3_running_var is changed to t_resnetv22_stage1_batchnorm3_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage1_conv3_weight is changed to t_resnetv22_stage1_conv3_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm0_gamma is changed to t_resnetv22_stage2_batchnorm0_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm0_beta is changed to t_resnetv22_stage2_batchnorm0_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm0_running_mean is changed to t_resnetv22_stage2_batchnorm0_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm0_running_var is changed to t_resnetv22_stage2_batchnorm0_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_conv0_weight is changed to t_resnetv22_stage2_conv0_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm1_gamma is changed to t_resnetv22_stage2_batchnorm1_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm1_beta is changed to t_resnetv22_stage2_batchnorm1_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm1_running_mean is changed to t_resnetv22_stage2_batchnorm1_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm1_running_var is changed to t_resnetv22_stage2_batchnorm1_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_conv1_weight is changed to t_resnetv22_stage2_conv1_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_conv2_weight is changed to t_resnetv22_stage2_conv2_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm2_gamma is changed to t_resnetv22_stage2_batchnorm2_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm2_beta is changed to t_resnetv22_stage2_batchnorm2_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm2_running_mean is changed to t_resnetv22_stage2_batchnorm2_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm2_running_var is changed to t_resnetv22_stage2_batchnorm2_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_conv3_weight is changed to t_resnetv22_stage2_conv3_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm3_gamma is changed to t_resnetv22_stage2_batchnorm3_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm3_beta is changed to t_resnetv22_stage2_batchnorm3_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm3_running_mean is changed to t_resnetv22_stage2_batchnorm3_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_batchnorm3_running_var is changed to t_resnetv22_stage2_batchnorm3_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage2_conv4_weight is changed to t_resnetv22_stage2_conv4_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm0_gamma is changed to t_resnetv22_stage3_batchnorm0_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm0_beta is changed to t_resnetv22_stage3_batchnorm0_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm0_running_mean is changed to t_resnetv22_stage3_batchnorm0_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm0_running_var is changed to t_resnetv22_stage3_batchnorm0_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_conv0_weight is changed to t_resnetv22_stage3_conv0_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm1_gamma is changed to t_resnetv22_stage3_batchnorm1_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm1_beta is changed to t_resnetv22_stage3_batchnorm1_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm1_running_mean is changed to t_resnetv22_stage3_batchnorm1_running_mean.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm1_running_var is changed to t_resnetv22_stage3_batchnorm1_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_conv1_weight is changed to t_resnetv22_stage3_conv1_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_conv2_weight is changed to t_resnetv22_stage3_conv2_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm2_gamma is changed to t_resnetv22_stage3_batchnorm2_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm2_beta is changed to t_resnetv22_stage3_batchnorm2_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm2_running_mean is changed to t_resnetv22_stage3_batchnorm2_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm2_running_var is changed to t_resnetv22_stage3_batchnorm2_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_conv3_weight is changed to t_resnetv22_stage3_conv3_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm3_gamma is changed to t_resnetv22_stage3_batchnorm3_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm3_beta is changed to t_resnetv22_stage3_batchnorm3_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm3_running_mean is changed to t_resnetv22_stage3_batchnorm3_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_batchnorm3_running_var is changed to t_resnetv22_stage3_batchnorm3_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage3_conv4_weight is changed to t_resnetv22_stage3_conv4_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm0_gamma is changed to t_resnetv22_stage4_batchnorm0_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm0_beta is changed to t_resnetv22_stage4_batchnorm0_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm0_running_mean is changed to t_resnetv22_stage4_batchnorm0_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm0_running_var is changed to t_resnetv22_stage4_batchnorm0_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_conv0_weight is changed to t_resnetv22_stage4_conv0_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm1_gamma is changed to t_resnetv22_stage4_batchnorm1_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm1_beta is changed to t_resnetv22_stage4_batchnorm1_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm1_running_mean is changed to t_resnetv22_stage4_batchnorm1_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm1_running_var is changed to t_resnetv22_stage4_batchnorm1_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_conv1_weight is changed to t_resnetv22_stage4_conv1_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_conv2_weight is changed to t_resnetv22_stage4_conv2_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm2_gamma is changed to t_resnetv22_stage4_batchnorm2_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm2_beta is changed to t_resnetv22_stage4_batchnorm2_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm2_running_mean is changed to t_resnetv22_stage4_batchnorm2_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm2_running_var is changed to t_resnetv22_stage4_batchnorm2_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_conv3_weight is changed to t_resnetv22_stage4_conv3_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm3_gamma is changed to t_resnetv22_stage4_batchnorm3_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm3_beta is changed to t_resnetv22_stage4_batchnorm3_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm3_running_mean is changed to t_resnetv22_stage4_batchnorm3_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_batchnorm3_running_var is changed to t_resnetv22_stage4_batchnorm3_running_var.\n",
      "WARNING:root:Tensor name t_resnetv22_stage4_conv4_weight is changed to t_resnetv22_stage4_conv4_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm2_gamma is changed to t_resnetv22_batchnorm2_gamma.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm2_beta is changed to t_resnetv22_batchnorm2_beta.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm2_running_mean is changed to t_resnetv22_batchnorm2_running_mean.\n",
      "WARNING:root:Tensor name t_resnetv22_batchnorm2_running_var is changed to t_resnetv22_batchnorm2_running_var.\n",
      "WARNING:root:Tensor name t_reshape_attr_tensor164 is changed to t_reshape_attr_tensor164.\n",
      "WARNING:root:Tensor name t_resnetv22_dense0_weight is changed to t_resnetv22_dense0_weight.\n",
      "WARNING:root:Tensor name t_resnetv22_dense0_bias is changed to t_resnetv22_dense0_bias.\n",
      "WARNING:root:Cannot get default value for dilations of Conv.\n",
      "WARNING:root:Cannot get default value for kernel_shape of Conv.\n",
      "WARNING:root:Cannot get default value for pads of Conv.\n",
      "WARNING:root:Cannot get default value for strides of Conv.\n",
      "WARNING:root:Cannot get default value for dilations of MaxPool.\n",
      "WARNING:root:Cannot get default value for kernel_shape of MaxPool.\n",
      "WARNING:root:Cannot get default value for pads of MaxPool.\n",
      "WARNING:root:Cannot get default value for strides of MaxPool.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Autogenerated by onnx-pytorch.\n",
      "\n",
      "import glob\n",
      "import os\n",
      "\n",
      "import numpy as np\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "\n",
      "class Model(nn.Module):\n",
      "  def __init__(self):\n",
      "    super(Model, self).__init__()\n",
      "    self.__vars = nn.ParameterDict()\n",
      "    for b in glob.glob(\n",
      "        os.path.join(os.path.dirname(__file__), \"variables\", \"*.npy\")):\n",
      "      v = torch.from_numpy(np.load(b))\n",
      "      requires_grad = v.dtype.is_floating_point or v.dtype.is_complex\n",
      "      self.__vars[os.path.basename(b)[:-4]] = nn.Parameter(\n",
      "          torch.from_numpy(np.load(b)), requires_grad=requires_grad)\n",
      "    self.n_n_resnetv22_batchnorm0_fwd = nn.BatchNorm2d(**{'num_features': 3, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_batchnorm0_fwd.weight.data = self.__vars[\"t_resnetv22_batchnorm0_gamma\"]\n",
      "    self.n_n_resnetv22_batchnorm0_fwd.bias.data = self.__vars[\"t_resnetv22_batchnorm0_beta\"]\n",
      "    self.n_n_resnetv22_batchnorm0_fwd.running_mean.data = self.__vars[\"t_resnetv22_batchnorm0_running_mean\"]\n",
      "    self.n_n_resnetv22_batchnorm0_fwd.running_var.data = self.__vars[\"t_resnetv22_batchnorm0_running_var\"]\n",
      "    self.n_n_resnetv22_conv0_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [3, 3], 'kernel_size': (7, 7), 'stride': [2, 2], 'in_channels': 3, 'bias': False})\n",
      "    self.n_n_resnetv22_conv0_fwd.weight.data = self.__vars[\"t_resnetv22_conv0_weight\"]\n",
      "    self.n_n_resnetv22_batchnorm1_fwd = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_batchnorm1_fwd.weight.data = self.__vars[\"t_resnetv22_batchnorm1_gamma\"]\n",
      "    self.n_n_resnetv22_batchnorm1_fwd.bias.data = self.__vars[\"t_resnetv22_batchnorm1_beta\"]\n",
      "    self.n_n_resnetv22_batchnorm1_fwd.running_mean.data = self.__vars[\"t_resnetv22_batchnorm1_running_mean\"]\n",
      "    self.n_n_resnetv22_batchnorm1_fwd.running_var.data = self.__vars[\"t_resnetv22_batchnorm1_running_var\"]\n",
      "    self.n_n_resnetv22_pool0_fwd = nn.MaxPool2d(**{'dilation': 1, 'kernel_size': [3, 3], 'ceil_mode': False, 'stride': [2, 2], 'return_indices': False})\n",
      "    self.n_n_resnetv22_stage1_batchnorm0_fwd = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_stage1_batchnorm0_fwd.weight.data = self.__vars[\"t_resnetv22_stage1_batchnorm0_gamma\"]\n",
      "    self.n_n_resnetv22_stage1_batchnorm0_fwd.bias.data = self.__vars[\"t_resnetv22_stage1_batchnorm0_beta\"]\n",
      "    self.n_n_resnetv22_stage1_batchnorm0_fwd.running_mean.data = self.__vars[\"t_resnetv22_stage1_batchnorm0_running_mean\"]\n",
      "    self.n_n_resnetv22_stage1_batchnorm0_fwd.running_var.data = self.__vars[\"t_resnetv22_stage1_batchnorm0_running_var\"]\n",
      "    self.n_n_resnetv22_stage1_conv0_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': False})\n",
      "    self.n_n_resnetv22_stage1_conv0_fwd.weight.data = self.__vars[\"t_resnetv22_stage1_conv0_weight\"]\n",
      "    self.n_n_resnetv22_stage1_batchnorm1_fwd = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_stage1_batchnorm1_fwd.weight.data = self.__vars[\"t_resnetv22_stage1_batchnorm1_gamma\"]\n",
      "    self.n_n_resnetv22_stage1_batchnorm1_fwd.bias.data = self.__vars[\"t_resnetv22_stage1_batchnorm1_beta\"]\n",
      "    self.n_n_resnetv22_stage1_batchnorm1_fwd.running_mean.data = self.__vars[\"t_resnetv22_stage1_batchnorm1_running_mean\"]\n",
      "    self.n_n_resnetv22_stage1_batchnorm1_fwd.running_var.data = self.__vars[\"t_resnetv22_stage1_batchnorm1_running_var\"]\n",
      "    self.n_n_resnetv22_stage1_conv1_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': False})\n",
      "    self.n_n_resnetv22_stage1_conv1_fwd.weight.data = self.__vars[\"t_resnetv22_stage1_conv1_weight\"]\n",
      "    self.n_n_resnetv22_stage1_batchnorm2_fwd = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_stage1_batchnorm2_fwd.weight.data = self.__vars[\"t_resnetv22_stage1_batchnorm2_gamma\"]\n",
      "    self.n_n_resnetv22_stage1_batchnorm2_fwd.bias.data = self.__vars[\"t_resnetv22_stage1_batchnorm2_beta\"]\n",
      "    self.n_n_resnetv22_stage1_batchnorm2_fwd.running_mean.data = self.__vars[\"t_resnetv22_stage1_batchnorm2_running_mean\"]\n",
      "    self.n_n_resnetv22_stage1_batchnorm2_fwd.running_var.data = self.__vars[\"t_resnetv22_stage1_batchnorm2_running_var\"]\n",
      "    self.n_n_resnetv22_stage1_conv2_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': False})\n",
      "    self.n_n_resnetv22_stage1_conv2_fwd.weight.data = self.__vars[\"t_resnetv22_stage1_conv2_weight\"]\n",
      "    self.n_n_resnetv22_stage1_batchnorm3_fwd = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_stage1_batchnorm3_fwd.weight.data = self.__vars[\"t_resnetv22_stage1_batchnorm3_gamma\"]\n",
      "    self.n_n_resnetv22_stage1_batchnorm3_fwd.bias.data = self.__vars[\"t_resnetv22_stage1_batchnorm3_beta\"]\n",
      "    self.n_n_resnetv22_stage1_batchnorm3_fwd.running_mean.data = self.__vars[\"t_resnetv22_stage1_batchnorm3_running_mean\"]\n",
      "    self.n_n_resnetv22_stage1_batchnorm3_fwd.running_var.data = self.__vars[\"t_resnetv22_stage1_batchnorm3_running_var\"]\n",
      "    self.n_n_resnetv22_stage1_conv3_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': False})\n",
      "    self.n_n_resnetv22_stage1_conv3_fwd.weight.data = self.__vars[\"t_resnetv22_stage1_conv3_weight\"]\n",
      "    self.n_n_resnetv22_stage2_batchnorm0_fwd = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_stage2_batchnorm0_fwd.weight.data = self.__vars[\"t_resnetv22_stage2_batchnorm0_gamma\"]\n",
      "    self.n_n_resnetv22_stage2_batchnorm0_fwd.bias.data = self.__vars[\"t_resnetv22_stage2_batchnorm0_beta\"]\n",
      "    self.n_n_resnetv22_stage2_batchnorm0_fwd.running_mean.data = self.__vars[\"t_resnetv22_stage2_batchnorm0_running_mean\"]\n",
      "    self.n_n_resnetv22_stage2_batchnorm0_fwd.running_var.data = self.__vars[\"t_resnetv22_stage2_batchnorm0_running_var\"]\n",
      "    self.n_n_resnetv22_stage2_conv0_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 64, 'bias': False})\n",
      "    self.n_n_resnetv22_stage2_conv0_fwd.weight.data = self.__vars[\"t_resnetv22_stage2_conv0_weight\"]\n",
      "    self.n_n_resnetv22_stage2_batchnorm1_fwd = nn.BatchNorm2d(**{'num_features': 128, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_stage2_batchnorm1_fwd.weight.data = self.__vars[\"t_resnetv22_stage2_batchnorm1_gamma\"]\n",
      "    self.n_n_resnetv22_stage2_batchnorm1_fwd.bias.data = self.__vars[\"t_resnetv22_stage2_batchnorm1_beta\"]\n",
      "    self.n_n_resnetv22_stage2_batchnorm1_fwd.running_mean.data = self.__vars[\"t_resnetv22_stage2_batchnorm1_running_mean\"]\n",
      "    self.n_n_resnetv22_stage2_batchnorm1_fwd.running_var.data = self.__vars[\"t_resnetv22_stage2_batchnorm1_running_var\"]\n",
      "    self.n_n_resnetv22_stage2_conv1_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 128, 'bias': False})\n",
      "    self.n_n_resnetv22_stage2_conv1_fwd.weight.data = self.__vars[\"t_resnetv22_stage2_conv1_weight\"]\n",
      "    self.n_n_resnetv22_stage2_conv2_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [2, 2], 'in_channels': 64, 'bias': False})\n",
      "    self.n_n_resnetv22_stage2_conv2_fwd.weight.data = self.__vars[\"t_resnetv22_stage2_conv2_weight\"]\n",
      "    self.n_n_resnetv22_stage2_batchnorm2_fwd = nn.BatchNorm2d(**{'num_features': 128, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_stage2_batchnorm2_fwd.weight.data = self.__vars[\"t_resnetv22_stage2_batchnorm2_gamma\"]\n",
      "    self.n_n_resnetv22_stage2_batchnorm2_fwd.bias.data = self.__vars[\"t_resnetv22_stage2_batchnorm2_beta\"]\n",
      "    self.n_n_resnetv22_stage2_batchnorm2_fwd.running_mean.data = self.__vars[\"t_resnetv22_stage2_batchnorm2_running_mean\"]\n",
      "    self.n_n_resnetv22_stage2_batchnorm2_fwd.running_var.data = self.__vars[\"t_resnetv22_stage2_batchnorm2_running_var\"]\n",
      "    self.n_n_resnetv22_stage2_conv3_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 128, 'bias': False})\n",
      "    self.n_n_resnetv22_stage2_conv3_fwd.weight.data = self.__vars[\"t_resnetv22_stage2_conv3_weight\"]\n",
      "    self.n_n_resnetv22_stage2_batchnorm3_fwd = nn.BatchNorm2d(**{'num_features': 128, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_stage2_batchnorm3_fwd.weight.data = self.__vars[\"t_resnetv22_stage2_batchnorm3_gamma\"]\n",
      "    self.n_n_resnetv22_stage2_batchnorm3_fwd.bias.data = self.__vars[\"t_resnetv22_stage2_batchnorm3_beta\"]\n",
      "    self.n_n_resnetv22_stage2_batchnorm3_fwd.running_mean.data = self.__vars[\"t_resnetv22_stage2_batchnorm3_running_mean\"]\n",
      "    self.n_n_resnetv22_stage2_batchnorm3_fwd.running_var.data = self.__vars[\"t_resnetv22_stage2_batchnorm3_running_var\"]\n",
      "    self.n_n_resnetv22_stage2_conv4_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 128, 'bias': False})\n",
      "    self.n_n_resnetv22_stage2_conv4_fwd.weight.data = self.__vars[\"t_resnetv22_stage2_conv4_weight\"]\n",
      "    self.n_n_resnetv22_stage3_batchnorm0_fwd = nn.BatchNorm2d(**{'num_features': 128, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_stage3_batchnorm0_fwd.weight.data = self.__vars[\"t_resnetv22_stage3_batchnorm0_gamma\"]\n",
      "    self.n_n_resnetv22_stage3_batchnorm0_fwd.bias.data = self.__vars[\"t_resnetv22_stage3_batchnorm0_beta\"]\n",
      "    self.n_n_resnetv22_stage3_batchnorm0_fwd.running_mean.data = self.__vars[\"t_resnetv22_stage3_batchnorm0_running_mean\"]\n",
      "    self.n_n_resnetv22_stage3_batchnorm0_fwd.running_var.data = self.__vars[\"t_resnetv22_stage3_batchnorm0_running_var\"]\n",
      "    self.n_n_resnetv22_stage3_conv0_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 128, 'bias': False})\n",
      "    self.n_n_resnetv22_stage3_conv0_fwd.weight.data = self.__vars[\"t_resnetv22_stage3_conv0_weight\"]\n",
      "    self.n_n_resnetv22_stage3_batchnorm1_fwd = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_stage3_batchnorm1_fwd.weight.data = self.__vars[\"t_resnetv22_stage3_batchnorm1_gamma\"]\n",
      "    self.n_n_resnetv22_stage3_batchnorm1_fwd.bias.data = self.__vars[\"t_resnetv22_stage3_batchnorm1_beta\"]\n",
      "    self.n_n_resnetv22_stage3_batchnorm1_fwd.running_mean.data = self.__vars[\"t_resnetv22_stage3_batchnorm1_running_mean\"]\n",
      "    self.n_n_resnetv22_stage3_batchnorm1_fwd.running_var.data = self.__vars[\"t_resnetv22_stage3_batchnorm1_running_var\"]\n",
      "    self.n_n_resnetv22_stage3_conv1_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': False})\n",
      "    self.n_n_resnetv22_stage3_conv1_fwd.weight.data = self.__vars[\"t_resnetv22_stage3_conv1_weight\"]\n",
      "    self.n_n_resnetv22_stage3_conv2_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [2, 2], 'in_channels': 128, 'bias': False})\n",
      "    self.n_n_resnetv22_stage3_conv2_fwd.weight.data = self.__vars[\"t_resnetv22_stage3_conv2_weight\"]\n",
      "    self.n_n_resnetv22_stage3_batchnorm2_fwd = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_stage3_batchnorm2_fwd.weight.data = self.__vars[\"t_resnetv22_stage3_batchnorm2_gamma\"]\n",
      "    self.n_n_resnetv22_stage3_batchnorm2_fwd.bias.data = self.__vars[\"t_resnetv22_stage3_batchnorm2_beta\"]\n",
      "    self.n_n_resnetv22_stage3_batchnorm2_fwd.running_mean.data = self.__vars[\"t_resnetv22_stage3_batchnorm2_running_mean\"]\n",
      "    self.n_n_resnetv22_stage3_batchnorm2_fwd.running_var.data = self.__vars[\"t_resnetv22_stage3_batchnorm2_running_var\"]\n",
      "    self.n_n_resnetv22_stage3_conv3_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': False})\n",
      "    self.n_n_resnetv22_stage3_conv3_fwd.weight.data = self.__vars[\"t_resnetv22_stage3_conv3_weight\"]\n",
      "    self.n_n_resnetv22_stage3_batchnorm3_fwd = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_stage3_batchnorm3_fwd.weight.data = self.__vars[\"t_resnetv22_stage3_batchnorm3_gamma\"]\n",
      "    self.n_n_resnetv22_stage3_batchnorm3_fwd.bias.data = self.__vars[\"t_resnetv22_stage3_batchnorm3_beta\"]\n",
      "    self.n_n_resnetv22_stage3_batchnorm3_fwd.running_mean.data = self.__vars[\"t_resnetv22_stage3_batchnorm3_running_mean\"]\n",
      "    self.n_n_resnetv22_stage3_batchnorm3_fwd.running_var.data = self.__vars[\"t_resnetv22_stage3_batchnorm3_running_var\"]\n",
      "    self.n_n_resnetv22_stage3_conv4_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': False})\n",
      "    self.n_n_resnetv22_stage3_conv4_fwd.weight.data = self.__vars[\"t_resnetv22_stage3_conv4_weight\"]\n",
      "    self.n_n_resnetv22_stage4_batchnorm0_fwd = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_stage4_batchnorm0_fwd.weight.data = self.__vars[\"t_resnetv22_stage4_batchnorm0_gamma\"]\n",
      "    self.n_n_resnetv22_stage4_batchnorm0_fwd.bias.data = self.__vars[\"t_resnetv22_stage4_batchnorm0_beta\"]\n",
      "    self.n_n_resnetv22_stage4_batchnorm0_fwd.running_mean.data = self.__vars[\"t_resnetv22_stage4_batchnorm0_running_mean\"]\n",
      "    self.n_n_resnetv22_stage4_batchnorm0_fwd.running_var.data = self.__vars[\"t_resnetv22_stage4_batchnorm0_running_var\"]\n",
      "    self.n_n_resnetv22_stage4_conv0_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 256, 'bias': False})\n",
      "    self.n_n_resnetv22_stage4_conv0_fwd.weight.data = self.__vars[\"t_resnetv22_stage4_conv0_weight\"]\n",
      "    self.n_n_resnetv22_stage4_batchnorm1_fwd = nn.BatchNorm2d(**{'num_features': 512, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_stage4_batchnorm1_fwd.weight.data = self.__vars[\"t_resnetv22_stage4_batchnorm1_gamma\"]\n",
      "    self.n_n_resnetv22_stage4_batchnorm1_fwd.bias.data = self.__vars[\"t_resnetv22_stage4_batchnorm1_beta\"]\n",
      "    self.n_n_resnetv22_stage4_batchnorm1_fwd.running_mean.data = self.__vars[\"t_resnetv22_stage4_batchnorm1_running_mean\"]\n",
      "    self.n_n_resnetv22_stage4_batchnorm1_fwd.running_var.data = self.__vars[\"t_resnetv22_stage4_batchnorm1_running_var\"]\n",
      "    self.n_n_resnetv22_stage4_conv1_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 512, 'bias': False})\n",
      "    self.n_n_resnetv22_stage4_conv1_fwd.weight.data = self.__vars[\"t_resnetv22_stage4_conv1_weight\"]\n",
      "    self.n_n_resnetv22_stage4_conv2_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [2, 2], 'in_channels': 256, 'bias': False})\n",
      "    self.n_n_resnetv22_stage4_conv2_fwd.weight.data = self.__vars[\"t_resnetv22_stage4_conv2_weight\"]\n",
      "    self.n_n_resnetv22_stage4_batchnorm2_fwd = nn.BatchNorm2d(**{'num_features': 512, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_stage4_batchnorm2_fwd.weight.data = self.__vars[\"t_resnetv22_stage4_batchnorm2_gamma\"]\n",
      "    self.n_n_resnetv22_stage4_batchnorm2_fwd.bias.data = self.__vars[\"t_resnetv22_stage4_batchnorm2_beta\"]\n",
      "    self.n_n_resnetv22_stage4_batchnorm2_fwd.running_mean.data = self.__vars[\"t_resnetv22_stage4_batchnorm2_running_mean\"]\n",
      "    self.n_n_resnetv22_stage4_batchnorm2_fwd.running_var.data = self.__vars[\"t_resnetv22_stage4_batchnorm2_running_var\"]\n",
      "    self.n_n_resnetv22_stage4_conv3_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 512, 'bias': False})\n",
      "    self.n_n_resnetv22_stage4_conv3_fwd.weight.data = self.__vars[\"t_resnetv22_stage4_conv3_weight\"]\n",
      "    self.n_n_resnetv22_stage4_batchnorm3_fwd = nn.BatchNorm2d(**{'num_features': 512, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_stage4_batchnorm3_fwd.weight.data = self.__vars[\"t_resnetv22_stage4_batchnorm3_gamma\"]\n",
      "    self.n_n_resnetv22_stage4_batchnorm3_fwd.bias.data = self.__vars[\"t_resnetv22_stage4_batchnorm3_beta\"]\n",
      "    self.n_n_resnetv22_stage4_batchnorm3_fwd.running_mean.data = self.__vars[\"t_resnetv22_stage4_batchnorm3_running_mean\"]\n",
      "    self.n_n_resnetv22_stage4_batchnorm3_fwd.running_var.data = self.__vars[\"t_resnetv22_stage4_batchnorm3_running_var\"]\n",
      "    self.n_n_resnetv22_stage4_conv4_fwd = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 512, 'bias': False})\n",
      "    self.n_n_resnetv22_stage4_conv4_fwd.weight.data = self.__vars[\"t_resnetv22_stage4_conv4_weight\"]\n",
      "    self.n_n_resnetv22_batchnorm2_fwd = nn.BatchNorm2d(**{'num_features': 512, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})\n",
      "    self.n_n_resnetv22_batchnorm2_fwd.weight.data = self.__vars[\"t_resnetv22_batchnorm2_gamma\"]\n",
      "    self.n_n_resnetv22_batchnorm2_fwd.bias.data = self.__vars[\"t_resnetv22_batchnorm2_beta\"]\n",
      "    self.n_n_resnetv22_batchnorm2_fwd.running_mean.data = self.__vars[\"t_resnetv22_batchnorm2_running_mean\"]\n",
      "    self.n_n_resnetv22_batchnorm2_fwd.running_var.data = self.__vars[\"t_resnetv22_batchnorm2_running_var\"]\n",
      "\n",
      "  def forward(self, *inputs):\n",
      "    t_data, = inputs\n",
      "    t_resnetv22_batchnorm0_fwd = self.n_n_resnetv22_batchnorm0_fwd(t_data)\n",
      "    t_resnetv22_conv0_fwd = self.n_n_resnetv22_conv0_fwd(t_resnetv22_batchnorm0_fwd)\n",
      "    t_resnetv22_batchnorm1_fwd = self.n_n_resnetv22_batchnorm1_fwd(t_resnetv22_conv0_fwd)\n",
      "    t_resnetv22_relu0_fwd = F.relu(t_resnetv22_batchnorm1_fwd)\n",
      "    t_resnetv22_relu0_fwd = F.pad(t_resnetv22_relu0_fwd, [1, 1, 1, 1], value=float('-inf'))\n",
      "    t_resnetv22_pool0_fwd = self.n_n_resnetv22_pool0_fwd(t_resnetv22_relu0_fwd)\n",
      "    t_resnetv22_stage1_batchnorm0_fwd = self.n_n_resnetv22_stage1_batchnorm0_fwd(t_resnetv22_pool0_fwd)\n",
      "    t_resnetv22_stage1_activation0 = F.relu(t_resnetv22_stage1_batchnorm0_fwd)\n",
      "    t_resnetv22_stage1_conv0_fwd = self.n_n_resnetv22_stage1_conv0_fwd(t_resnetv22_stage1_activation0)\n",
      "    t_resnetv22_stage1_batchnorm1_fwd = self.n_n_resnetv22_stage1_batchnorm1_fwd(t_resnetv22_stage1_conv0_fwd)\n",
      "    t_resnetv22_stage1_activation1 = F.relu(t_resnetv22_stage1_batchnorm1_fwd)\n",
      "    t_resnetv22_stage1_conv1_fwd = self.n_n_resnetv22_stage1_conv1_fwd(t_resnetv22_stage1_activation1)\n",
      "    t_resnetv22_stage1__plus0 = t_resnetv22_stage1_conv1_fwd + t_resnetv22_pool0_fwd\n",
      "    t_resnetv22_stage1_batchnorm2_fwd = self.n_n_resnetv22_stage1_batchnorm2_fwd(t_resnetv22_stage1__plus0)\n",
      "    t_resnetv22_stage1_activation2 = F.relu(t_resnetv22_stage1_batchnorm2_fwd)\n",
      "    t_resnetv22_stage1_conv2_fwd = self.n_n_resnetv22_stage1_conv2_fwd(t_resnetv22_stage1_activation2)\n",
      "    t_resnetv22_stage1_batchnorm3_fwd = self.n_n_resnetv22_stage1_batchnorm3_fwd(t_resnetv22_stage1_conv2_fwd)\n",
      "    t_resnetv22_stage1_activation3 = F.relu(t_resnetv22_stage1_batchnorm3_fwd)\n",
      "    t_resnetv22_stage1_conv3_fwd = self.n_n_resnetv22_stage1_conv3_fwd(t_resnetv22_stage1_activation3)\n",
      "    t_resnetv22_stage1__plus1 = t_resnetv22_stage1_conv3_fwd + t_resnetv22_stage1__plus0\n",
      "    t_resnetv22_stage2_batchnorm0_fwd = self.n_n_resnetv22_stage2_batchnorm0_fwd(t_resnetv22_stage1__plus1)\n",
      "    t_resnetv22_stage2_activation0 = F.relu(t_resnetv22_stage2_batchnorm0_fwd)\n",
      "    t_resnetv22_stage2_conv0_fwd = self.n_n_resnetv22_stage2_conv0_fwd(t_resnetv22_stage2_activation0)\n",
      "    t_resnetv22_stage2_batchnorm1_fwd = self.n_n_resnetv22_stage2_batchnorm1_fwd(t_resnetv22_stage2_conv0_fwd)\n",
      "    t_resnetv22_stage2_activation1 = F.relu(t_resnetv22_stage2_batchnorm1_fwd)\n",
      "    t_resnetv22_stage2_conv1_fwd = self.n_n_resnetv22_stage2_conv1_fwd(t_resnetv22_stage2_activation1)\n",
      "    t_resnetv22_stage2_conv2_fwd = self.n_n_resnetv22_stage2_conv2_fwd(t_resnetv22_stage2_activation0)\n",
      "    t_resnetv22_stage2__plus0 = t_resnetv22_stage2_conv1_fwd + t_resnetv22_stage2_conv2_fwd\n",
      "    t_resnetv22_stage2_batchnorm2_fwd = self.n_n_resnetv22_stage2_batchnorm2_fwd(t_resnetv22_stage2__plus0)\n",
      "    t_resnetv22_stage2_activation2 = F.relu(t_resnetv22_stage2_batchnorm2_fwd)\n",
      "    t_resnetv22_stage2_conv3_fwd = self.n_n_resnetv22_stage2_conv3_fwd(t_resnetv22_stage2_activation2)\n",
      "    t_resnetv22_stage2_batchnorm3_fwd = self.n_n_resnetv22_stage2_batchnorm3_fwd(t_resnetv22_stage2_conv3_fwd)\n",
      "    t_resnetv22_stage2_activation3 = F.relu(t_resnetv22_stage2_batchnorm3_fwd)\n",
      "    t_resnetv22_stage2_conv4_fwd = self.n_n_resnetv22_stage2_conv4_fwd(t_resnetv22_stage2_activation3)\n",
      "    t_resnetv22_stage2__plus1 = t_resnetv22_stage2_conv4_fwd + t_resnetv22_stage2__plus0\n",
      "    t_resnetv22_stage3_batchnorm0_fwd = self.n_n_resnetv22_stage3_batchnorm0_fwd(t_resnetv22_stage2__plus1)\n",
      "    t_resnetv22_stage3_activation0 = F.relu(t_resnetv22_stage3_batchnorm0_fwd)\n",
      "    t_resnetv22_stage3_conv0_fwd = self.n_n_resnetv22_stage3_conv0_fwd(t_resnetv22_stage3_activation0)\n",
      "    t_resnetv22_stage3_batchnorm1_fwd = self.n_n_resnetv22_stage3_batchnorm1_fwd(t_resnetv22_stage3_conv0_fwd)\n",
      "    t_resnetv22_stage3_activation1 = F.relu(t_resnetv22_stage3_batchnorm1_fwd)\n",
      "    t_resnetv22_stage3_conv1_fwd = self.n_n_resnetv22_stage3_conv1_fwd(t_resnetv22_stage3_activation1)\n",
      "    t_resnetv22_stage3_conv2_fwd = self.n_n_resnetv22_stage3_conv2_fwd(t_resnetv22_stage3_activation0)\n",
      "    t_resnetv22_stage3__plus0 = t_resnetv22_stage3_conv1_fwd + t_resnetv22_stage3_conv2_fwd\n",
      "    t_resnetv22_stage3_batchnorm2_fwd = self.n_n_resnetv22_stage3_batchnorm2_fwd(t_resnetv22_stage3__plus0)\n",
      "    t_resnetv22_stage3_activation2 = F.relu(t_resnetv22_stage3_batchnorm2_fwd)\n",
      "    t_resnetv22_stage3_conv3_fwd = self.n_n_resnetv22_stage3_conv3_fwd(t_resnetv22_stage3_activation2)\n",
      "    t_resnetv22_stage3_batchnorm3_fwd = self.n_n_resnetv22_stage3_batchnorm3_fwd(t_resnetv22_stage3_conv3_fwd)\n",
      "    t_resnetv22_stage3_activation3 = F.relu(t_resnetv22_stage3_batchnorm3_fwd)\n",
      "    t_resnetv22_stage3_conv4_fwd = self.n_n_resnetv22_stage3_conv4_fwd(t_resnetv22_stage3_activation3)\n",
      "    t_resnetv22_stage3__plus1 = t_resnetv22_stage3_conv4_fwd + t_resnetv22_stage3__plus0\n",
      "    t_resnetv22_stage4_batchnorm0_fwd = self.n_n_resnetv22_stage4_batchnorm0_fwd(t_resnetv22_stage3__plus1)\n",
      "    t_resnetv22_stage4_activation0 = F.relu(t_resnetv22_stage4_batchnorm0_fwd)\n",
      "    t_resnetv22_stage4_conv0_fwd = self.n_n_resnetv22_stage4_conv0_fwd(t_resnetv22_stage4_activation0)\n",
      "    t_resnetv22_stage4_batchnorm1_fwd = self.n_n_resnetv22_stage4_batchnorm1_fwd(t_resnetv22_stage4_conv0_fwd)\n",
      "    t_resnetv22_stage4_activation1 = F.relu(t_resnetv22_stage4_batchnorm1_fwd)\n",
      "    t_resnetv22_stage4_conv1_fwd = self.n_n_resnetv22_stage4_conv1_fwd(t_resnetv22_stage4_activation1)\n",
      "    t_resnetv22_stage4_conv2_fwd = self.n_n_resnetv22_stage4_conv2_fwd(t_resnetv22_stage4_activation0)\n",
      "    t_resnetv22_stage4__plus0 = t_resnetv22_stage4_conv1_fwd + t_resnetv22_stage4_conv2_fwd\n",
      "    t_resnetv22_stage4_batchnorm2_fwd = self.n_n_resnetv22_stage4_batchnorm2_fwd(t_resnetv22_stage4__plus0)\n",
      "    t_resnetv22_stage4_activation2 = F.relu(t_resnetv22_stage4_batchnorm2_fwd)\n",
      "    t_resnetv22_stage4_conv3_fwd = self.n_n_resnetv22_stage4_conv3_fwd(t_resnetv22_stage4_activation2)\n",
      "    t_resnetv22_stage4_batchnorm3_fwd = self.n_n_resnetv22_stage4_batchnorm3_fwd(t_resnetv22_stage4_conv3_fwd)\n",
      "    t_resnetv22_stage4_activation3 = F.relu(t_resnetv22_stage4_batchnorm3_fwd)\n",
      "    t_resnetv22_stage4_conv4_fwd = self.n_n_resnetv22_stage4_conv4_fwd(t_resnetv22_stage4_activation3)\n",
      "    t_resnetv22_stage4__plus1 = t_resnetv22_stage4_conv4_fwd + t_resnetv22_stage4__plus0\n",
      "    t_resnetv22_batchnorm2_fwd = self.n_n_resnetv22_batchnorm2_fwd(t_resnetv22_stage4__plus1)\n",
      "    t_resnetv22_relu1_fwd = F.relu(t_resnetv22_batchnorm2_fwd)\n",
      "    t_resnetv22_pool1_fwd = F.avg_pool2d(t_resnetv22_relu1_fwd, **{'kernel_size': t_resnetv22_relu1_fwd.shape[-2:]})\n",
      "    shape_t_resnetv22_pool1_fwd = [s if s != 0 else t_resnetv22_pool1_fwd.shape[i] for i, s in enumerate(self.__vars[\"t_reshape_attr_tensor164\"])]\n",
      "    t_resnetv22_flatten0_reshape0 = torch.reshape(t_resnetv22_pool1_fwd, shape_t_resnetv22_pool1_fwd)\n",
      "    t_resnetv22_dense0_fwd = 1.0 * torch.matmul(t_resnetv22_flatten0_reshape0, torch.transpose(self.__vars[\"t_resnetv22_dense0_weight\"], 0, 1)) + 1.0 * self.__vars[\"t_resnetv22_dense0_bias\"]\n",
      "    return t_resnetv22_dense0_fwd\n",
      "\n",
      "\n",
      "@torch.no_grad()\n",
      "def test_run_model(inputs=[torch.from_numpy(np.random.randn(*[1, 3, 224, 224]).astype(np.float32))]):\n",
      "  model = Model()\n",
      "  model.eval()\n",
      "  print(model)\n",
      "  rs = model(*inputs)\n",
      "  print(rs)\n",
      "  return rs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------Forward Pass - Training------------------------------------------------------\n",
      "             Layer (type)     Output Shape     Params        Addition  Multiplication    Logical     Sq inv   Division\n",
      "======================================================================================================================\n",
      "            BatchNorm2d-1  [3, 3, 224, 224]          6         903,171       1,354,770          0          3          0\n",
      "                 Conv2d-2  [3, 64, 112, 112]      9,408     351,633,408     354,041,856          0          0          0\n",
      "            BatchNorm2d-3  [3, 64, 112, 112]        128       4,816,960       7,225,728          0         64          0\n",
      "              MaxPool2d-4  [3, 64, 56, 56]          0               0               0  4,816,896          0          0\n",
      "            BatchNorm2d-5  [3, 64, 56, 56]        128       1,204,288       1,806,720          0         64          0\n",
      "                 Conv2d-6  [3, 64, 56, 56]     36,864     346,214,400     346,816,512          0          0          0\n",
      "            BatchNorm2d-7  [3, 64, 56, 56]        128       1,204,288       1,806,720          0         64          0\n",
      "                 Conv2d-8  [3, 64, 56, 56]     36,864     346,214,400     346,816,512          0          0          0\n",
      "            BatchNorm2d-9  [3, 64, 56, 56]        128       1,204,288       1,806,720          0         64          0\n",
      "                Conv2d-10  [3, 64, 56, 56]     36,864     346,214,400     346,816,512          0          0          0\n",
      "           BatchNorm2d-11  [3, 64, 56, 56]        128       1,204,288       1,806,720          0         64          0\n",
      "                Conv2d-12  [3, 64, 56, 56]     36,864     346,214,400     346,816,512          0          0          0\n",
      "           BatchNorm2d-13  [3, 64, 56, 56]        128       1,204,288       1,806,720          0         64          0\n",
      "                Conv2d-14  [3, 128, 28, 28]     73,728     173,107,200     173,408,256          0          0          0\n",
      "           BatchNorm2d-15  [3, 128, 28, 28]        256         602,240         903,936          0        128          0\n",
      "                Conv2d-16  [3, 128, 28, 28]    147,456     346,515,456     346,816,512          0          0          0\n",
      "                Conv2d-17  [3, 128, 28, 28]      8,192      18,966,528      19,267,584          0          0          0\n",
      "           BatchNorm2d-18  [3, 128, 28, 28]        256         602,240         903,936          0        128          0\n",
      "                Conv2d-19  [3, 128, 28, 28]    147,456     346,515,456     346,816,512          0          0          0\n",
      "           BatchNorm2d-20  [3, 128, 28, 28]        256         602,240         903,936          0        128          0\n",
      "                Conv2d-21  [3, 128, 28, 28]    147,456     346,515,456     346,816,512          0          0          0\n",
      "           BatchNorm2d-22  [3, 128, 28, 28]        256         602,240         903,936          0        128          0\n",
      "                Conv2d-23  [3, 256, 14, 14]    294,912     173,257,728     173,408,256          0          0          0\n",
      "           BatchNorm2d-24  [3, 256, 14, 14]        512         301,312         453,120          0        256          0\n",
      "                Conv2d-25  [3, 256, 14, 14]    589,824     346,665,984     346,816,512          0          0          0\n",
      "                Conv2d-26  [3, 256, 14, 14]     32,768      19,117,056      19,267,584          0          0          0\n",
      "           BatchNorm2d-27  [3, 256, 14, 14]        512         301,312         453,120          0        256          0\n",
      "                Conv2d-28  [3, 256, 14, 14]    589,824     346,665,984     346,816,512          0          0          0\n",
      "           BatchNorm2d-29  [3, 256, 14, 14]        512         301,312         453,120          0        256          0\n",
      "                Conv2d-30  [3, 256, 14, 14]    589,824     346,665,984     346,816,512          0          0          0\n",
      "           BatchNorm2d-31  [3, 256, 14, 14]        512         301,312         453,120          0        256          0\n",
      "                Conv2d-32   [3, 512, 7, 7]  1,179,648     173,332,992     173,408,256          0          0          0\n",
      "           BatchNorm2d-33   [3, 512, 7, 7]      1,024         151,040         228,864          0        512          0\n",
      "                Conv2d-34   [3, 512, 7, 7]  2,359,296     346,741,248     346,816,512          0          0          0\n",
      "                Conv2d-35   [3, 512, 7, 7]    131,072      19,192,320      19,267,584          0          0          0\n",
      "           BatchNorm2d-36   [3, 512, 7, 7]      1,024         151,040         228,864          0        512          0\n",
      "                Conv2d-37   [3, 512, 7, 7]  2,359,296     346,741,248     346,816,512          0          0          0\n",
      "           BatchNorm2d-38   [3, 512, 7, 7]      1,024         151,040         228,864          0        512          0\n",
      "                Conv2d-39   [3, 512, 7, 7]  2,359,296     346,741,248     346,816,512          0          0          0\n",
      "           BatchNorm2d-40   [3, 512, 7, 7]      1,024         151,040         228,864          0        512          0\n",
      "======================================================================================================================\n",
      "Total params: 11,174,854\n",
      "Total FLOPs: 10,918,655,512\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.43\n",
      "Forward pass size (MB): 30.58\n",
      "Params size (MB): 10.66\n",
      "Estimated Total Size (MB): 41.66\n",
      "FLOPs size (GB): 10.92\n",
      "----------------------------------------------------------------\n",
      "-----------------------------------------Forward Pass - Inference-----------------------------------------------------\n",
      "             Layer (type)     Output Shape        Addition  Multiplication    Logical     Sq inv   Division\n",
      "======================================================================================================================\n",
      "            BatchNorm2d-1  [3, 3, 224, 224]         602,118         301,062          0          6          0\n",
      "                 Conv2d-2  [3, 64, 112, 112]     117,211,136     118,013,952          0          0          0\n",
      "            BatchNorm2d-3  [3, 64, 112, 112]       3,211,392       1,605,760          0        128          0\n",
      "              MaxPool2d-4  [3, 64, 56, 56]               0               0  1,605,632          0          0\n",
      "            BatchNorm2d-5  [3, 64, 56, 56]         802,944         401,536          0        128          0\n",
      "                 Conv2d-6  [3, 64, 56, 56]     115,404,800     115,605,504          0          0          0\n",
      "            BatchNorm2d-7  [3, 64, 56, 56]         802,944         401,536          0        128          0\n",
      "                 Conv2d-8  [3, 64, 56, 56]     115,404,800     115,605,504          0          0          0\n",
      "            BatchNorm2d-9  [3, 64, 56, 56]         802,944         401,536          0        128          0\n",
      "                Conv2d-10  [3, 64, 56, 56]     115,404,800     115,605,504          0          0          0\n",
      "           BatchNorm2d-11  [3, 64, 56, 56]         802,944         401,536          0        128          0\n",
      "                Conv2d-12  [3, 64, 56, 56]     115,404,800     115,605,504          0          0          0\n",
      "           BatchNorm2d-13  [3, 64, 56, 56]         802,944         401,536          0        128          0\n",
      "                Conv2d-14  [3, 128, 28, 28]      57,702,400      57,802,752          0          0          0\n",
      "           BatchNorm2d-15  [3, 128, 28, 28]         401,664         200,960          0        256          0\n",
      "                Conv2d-16  [3, 128, 28, 28]     115,505,152     115,605,504          0          0          0\n",
      "                Conv2d-17  [3, 128, 28, 28]       6,322,176       6,422,528          0          0          0\n",
      "           BatchNorm2d-18  [3, 128, 28, 28]         401,664         200,960          0        256          0\n",
      "                Conv2d-19  [3, 128, 28, 28]     115,505,152     115,605,504          0          0          0\n",
      "           BatchNorm2d-20  [3, 128, 28, 28]         401,664         200,960          0        256          0\n",
      "                Conv2d-21  [3, 128, 28, 28]     115,505,152     115,605,504          0          0          0\n",
      "           BatchNorm2d-22  [3, 128, 28, 28]         401,664         200,960          0        256          0\n",
      "                Conv2d-23  [3, 256, 14, 14]      57,752,576      57,802,752          0          0          0\n",
      "           BatchNorm2d-24  [3, 256, 14, 14]         201,216         100,864          0        512          0\n",
      "                Conv2d-25  [3, 256, 14, 14]     115,555,328     115,605,504          0          0          0\n",
      "                Conv2d-26  [3, 256, 14, 14]       6,372,352       6,422,528          0          0          0\n",
      "           BatchNorm2d-27  [3, 256, 14, 14]         201,216         100,864          0        512          0\n",
      "                Conv2d-28  [3, 256, 14, 14]     115,555,328     115,605,504          0          0          0\n",
      "           BatchNorm2d-29  [3, 256, 14, 14]         201,216         100,864          0        512          0\n",
      "                Conv2d-30  [3, 256, 14, 14]     115,555,328     115,605,504          0          0          0\n",
      "           BatchNorm2d-31  [3, 256, 14, 14]         201,216         100,864          0        512          0\n",
      "                Conv2d-32   [3, 512, 7, 7]      57,777,664      57,802,752          0          0          0\n",
      "           BatchNorm2d-33   [3, 512, 7, 7]         101,376          51,200          0      1,024          0\n",
      "                Conv2d-34   [3, 512, 7, 7]     115,580,416     115,605,504          0          0          0\n",
      "                Conv2d-35   [3, 512, 7, 7]       6,397,440       6,422,528          0          0          0\n",
      "           BatchNorm2d-36   [3, 512, 7, 7]         101,376          51,200          0      1,024          0\n",
      "                Conv2d-37   [3, 512, 7, 7]     115,580,416     115,605,504          0          0          0\n",
      "           BatchNorm2d-38   [3, 512, 7, 7]         101,376          51,200          0      1,024          0\n",
      "                Conv2d-39   [3, 512, 7, 7]     115,580,416     115,605,504          0          0          0\n",
      "           BatchNorm2d-40   [3, 512, 7, 7]         101,376          51,200          0      1,024          0\n",
      "======================================================================================================================\n",
      "Total FLOPs: 3,642,224,402\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.43\n",
      "Forward pass size (MB): 30.58\n",
      "FLOPs size (GB): 3.64\n",
      "----------------------------------------------------------------\n",
      "-----------------------------------------------Backward Pass----------------------------------------------------------\n",
      "             Layer (type)     Output Shape        Addition  Multiplication    Logical     Sq inv   Division\n",
      "======================================================================================================================\n",
      "           BatchNorm2d-40   [3, 512, 7, 7]         600,064         530,944          0          0          0\n",
      "                Conv2d-39   [3, 512, 7, 7]     686,479,872     693,633,024          0          0          0\n",
      "           BatchNorm2d-38   [3, 512, 7, 7]         600,064         530,944          0          0          0\n",
      "                Conv2d-37   [3, 512, 7, 7]     686,479,872     693,633,024          0          0          0\n",
      "           BatchNorm2d-36   [3, 512, 7, 7]         600,064         530,944          0          0          0\n",
      "                Conv2d-35   [3, 512, 7, 7]      37,991,424      38,535,168          0          0          0\n",
      "                Conv2d-34   [3, 512, 7, 7]     686,479,872     693,633,024          0          0          0\n",
      "           BatchNorm2d-33   [3, 512, 7, 7]         600,064         530,944          0          0          0\n",
      "                Conv2d-32   [3, 512, 7, 7]     343,127,040     346,816,512          0          0          0\n",
      "           BatchNorm2d-31  [3, 256, 14, 14]       1,203,200       1,055,744          0          0          0\n",
      "                Conv2d-30  [3, 256, 14, 14]     691,713,024     693,633,024          0          0          0\n",
      "           BatchNorm2d-29  [3, 256, 14, 14]       1,203,200       1,055,744          0          0          0\n",
      "                Conv2d-28  [3, 256, 14, 14]     691,713,024     693,633,024          0          0          0\n",
      "           BatchNorm2d-27  [3, 256, 14, 14]       1,203,200       1,055,744          0          0          0\n",
      "                Conv2d-26  [3, 256, 14, 14]      38,135,808      38,535,168          0          0          0\n",
      "                Conv2d-25  [3, 256, 14, 14]     691,713,024     693,633,024          0          0          0\n",
      "           BatchNorm2d-24  [3, 256, 14, 14]       1,203,200       1,055,744          0          0          0\n",
      "                Conv2d-23  [3, 256, 14, 14]     345,630,720     346,816,512          0          0          0\n",
      "           BatchNorm2d-22  [3, 128, 28, 28]       2,407,936       2,108,416          0          0          0\n",
      "                Conv2d-21  [3, 128, 28, 28]     692,889,600     693,633,024          0          0          0\n",
      "           BatchNorm2d-20  [3, 128, 28, 28]       2,407,936       2,108,416          0          0          0\n",
      "                Conv2d-19  [3, 128, 28, 28]     692,889,600     693,633,024          0          0          0\n",
      "           BatchNorm2d-18  [3, 128, 28, 28]       2,407,936       2,108,416          0          0          0\n",
      "                Conv2d-17  [3, 128, 28, 28]      37,908,480      38,535,168          0          0          0\n",
      "                Conv2d-16  [3, 128, 28, 28]     692,889,600     693,633,024          0          0          0\n",
      "           BatchNorm2d-15  [3, 128, 28, 28]       2,407,936       2,108,416          0          0          0\n",
      "                Conv2d-14  [3, 128, 28, 28]     345,993,216     346,816,512          0          0          0\n",
      "           BatchNorm2d-13  [3, 64, 56, 56]       4,816,640       4,215,296          0          0          0\n",
      "                Conv2d-12  [3, 64, 56, 56]     692,920,320     693,633,024          0          0          0\n",
      "           BatchNorm2d-11  [3, 64, 56, 56]       4,816,640       4,215,296          0          0          0\n",
      "                Conv2d-10  [3, 64, 56, 56]     692,920,320     693,633,024          0          0          0\n",
      "            BatchNorm2d-9  [3, 64, 56, 56]       4,816,640       4,215,296          0          0          0\n",
      "                 Conv2d-8  [3, 64, 56, 56]     692,920,320     693,633,024          0          0          0\n",
      "            BatchNorm2d-7  [3, 64, 56, 56]       4,816,640       4,215,296          0          0          0\n",
      "                 Conv2d-6  [3, 64, 56, 56]     692,920,320     693,633,024          0          0          0\n",
      "            BatchNorm2d-5  [3, 64, 56, 56]       4,816,640       4,215,296          0          0          0\n",
      "              MaxPool2d-4  [3, 64, 56, 56]         602,112               0          0          0          0\n",
      "            BatchNorm2d-3  [3, 64, 112, 112]      19,267,328      16,859,648          0          0          0\n",
      "                 Conv2d-2  [3, 64, 112, 112]     707,603,904     708,083,712          0          0          0\n",
      "            BatchNorm2d-1  [3, 3, 224, 224]       3,612,660       3,161,112          0          0          0\n",
      "======================================================================================================\n",
      "Total FLOPs: 21,842,975,180\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.43\n",
      "Backward pass size (MB): 30.58\n",
      "FLOPs size (GB): 21.84\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kings\\anaconda3\\envs\\python_programs\\lib\\site-packages\\torch\\nn\\modules\\module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    }
   ],
   "source": [
    "from onnx_pytorch import code_gen\n",
    "convert = code_gen.gen(\"resnet18-v2-7.onnx\", \"./\")\n",
    "from model import Model\n",
    "net = Model()\n",
    "scope(net, input_size=(3, 224, 224), batch_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ab6e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Dropout2d(p=0.2)\n",
    "input = torch.randn(20, 16, 32, 32)\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d1f4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5.])\n",
      "tensor([1.6667, 3.3333, 0.0000, 0.0000, 8.3333])\n",
      "tensor([1., 2., 3., 4., 5.])\n",
      "tensor([1.6667, 3.3333, 5.0000, 6.6667, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "inp = torch.tensor([1.0, 2.0, 3, 4, 5])\n",
    "\n",
    "outplace_dropout = nn.Dropout(p=0.4)\n",
    "print(inp)\n",
    "output = outplace_dropout(inp)\n",
    "print(output)\n",
    "print(inp) # Notice that the input doesn't get changed here\n",
    "\n",
    "\n",
    "inplace_droput = nn.Dropout(p=0.4, inplace=True)\n",
    "inplace_droput(inp)\n",
    "print(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b979a722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "m1 = nn.Linear(120, 80)\n",
    "m2 = nn.Dropout(p=0.2)\n",
    "m3 = nn.Linear(80, 10)\n",
    "x = torch.randn(10, 120)\n",
    "y = m3(m2(m1(x)))\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412780f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 120])\n",
      "torch.Size([10, 80])\n"
     ]
    }
   ],
   "source": [
    "print(m1.weight.size())\n",
    "print(m3.weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f30bac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "782b032b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26ff0086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71683054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "050ba2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "m = nn.ReLU(inplace=True)\n",
    "print(m.inplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31afae4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "m.inplace= False\n",
    "print(m.inplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6902d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
