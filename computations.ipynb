{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a78f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18800f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = [\"compute_flops\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc763edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_flops(module, inp, out, batch_size = 1, p = 'f', mode = 'train'):\n",
    "    res = OrderedDict()\n",
    "    res['add'] = 0\n",
    "    res['mul'] = 0\n",
    "    res['log'] = 0\n",
    "    res['div'] = 0\n",
    "    res['sq_inv'] = 0\n",
    "    res['exp'] = 0\n",
    "    res['logar'] = 0\n",
    "    res['inv'] = 0\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        add, mul = compute_Conv2d_flops(module, inp, out, passing = p)\n",
    "        res['add'] = add*batch_size//2\n",
    "        res['mul'] = mul*batch_size//2\n",
    "        return res\n",
    "    elif isinstance(module, nn.BatchNorm2d):\n",
    "        if p == 'f':\n",
    "            if mode == 'train':\n",
    "                add, mul, sq_inv = compute_BatchNorm2d_flops(module, inp, out, b_sz = batch_size)\n",
    "            else:\n",
    "                add, mul, sq_inv = compute_BatchNorm2d_flops(module, inp, out, b_sz = batch_size, mode = 'infer')\n",
    "        else:\n",
    "            add, mul, sq_inv = compute_BatchNorm2d_flops(module, inp, out, b_sz = batch_size, passing = 'b')\n",
    "        res['add'] = add\n",
    "        res['mul'] = mul\n",
    "        res['sq_inv'] = sq_inv\n",
    "        return res\n",
    "    elif isinstance(module,  nn.MaxPool2d):\n",
    "        if p == 'f':\n",
    "            res['log'] = compute_Pool2d_flops(module, inp, out)*batch_size//2\n",
    "        else:\n",
    "            res['add'] = compute_Pool2d_flops(module, inp, out, passing = 'b')*batch_size//2\n",
    "        return res\n",
    "    elif isinstance(module, (nn.ReLU, nn.ReLU6, nn.PReLU, nn.ELU, nn.LeakyReLU)):\n",
    "        res['log'] = compute_ReLU_flops(module, inp, out)*batch_size//2\n",
    "        return res\n",
    "    elif isinstance(module,  nn.AdaptiveAvgPool2d):\n",
    "        add, div = compute_AvgPool2d_flops(module, inp, out, passing = p)\n",
    "        res['add'] = add*batch_size\n",
    "        res['div'] = div*batch_size\n",
    "        return res\n",
    "    elif isinstance(module, (nn.ReLU, nn.ReLU6, nn.ELU, nn.LeakyReLU)):\n",
    "        res['log'] = compute_ReLU_flops(module, inp, out, passing = p)*batch_size//2\n",
    "        return res\n",
    "    elif isinstance(module, nn.PReLU):\n",
    "        log, mul, add = compute_PReLU_flops(module, inp, out, passing = p)*batch_size//2\n",
    "        res['log'] = log\n",
    "        res['mul'] = mul\n",
    "        res['add'] = add\n",
    "        return res\n",
    "    elif isinstance(module, nn.Tanh):\n",
    "        exp, mul, add, div = compute_PReLU_flops(module, inp, out, passing = p)*batch_size//2\n",
    "        res['exp'] = exp\n",
    "        res['mul'] = mul\n",
    "        res['add'] = add\n",
    "        res['div'] = div\n",
    "        return res\n",
    "    elif isinstance(module, nn.Softplus):\n",
    "        exp, logar, add, div = compute_Softplus_flops(module, _inp, _out, passing = p)*batch_size//2\n",
    "        res['exp'] = exp\n",
    "        res['logar'] = logar\n",
    "        res['add'] = add\n",
    "        res['div'] = div\n",
    "        return res\n",
    "    elif isinstance(module, nn.Sigmoid):\n",
    "        exp, mul, add, div = compute_Sigmoid_flops(module, _inp, _out, passing = p)*batch_size//2\n",
    "        res['exp'] = exp\n",
    "        res['mul'] = mul\n",
    "        res['add'] = add\n",
    "        res['div'] = div\n",
    "        return res\n",
    "    elif isinstance(module, nn.Softmax):\n",
    "        exp, mul, add, inv = compute_Sigmoid_flops(module, _inp, _out, passing = p)*batch_size//2\n",
    "        res['exp'] = exp\n",
    "        res['mul'] = mul\n",
    "        res['add'] = add\n",
    "        res['inv'] = inv\n",
    "        return res\n",
    "#     elif isinstance(module, nn.Upsample):\n",
    "#         return compute_Upsample_flops(module, inp, out) // 2\n",
    "    elif isinstance(module, nn.Linear):\n",
    "        add, mul = compute_Linear_flops(module, inp, out, passing = p)\n",
    "        res['add'] = add*batch_size//2\n",
    "        res['mul'] = mul*batch_size//2\n",
    "        return res\n",
    "    elif isinstance(module, (nn.Dropout, nn.Dropout2d)):\n",
    "        res['mul'] = compute_Dropout_flops(module, inp, out)\n",
    "        return res\n",
    "    else:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b70b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_params(module, inp, out, p = 'f'):\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        return compute_Conv2d_params(module, inp, out, passing = p)\n",
    "    elif isinstance(module, nn.BatchNorm2d):\n",
    "        return compute_BatchNorm2d_params(module, inp, out, passing = p)\n",
    "    elif isinstance(module, nn.Linear):\n",
    "        return compute_Linear_params(module, inp, out, passing = p)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d40ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fmap(module, inp, out, l, batch_size = 1, p = 'f'):\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        return compute_Conv2d_fmap(module, inp, out, layer = l, passing = p)*batch_size\n",
    "    elif isinstance(module, nn.BatchNorm2d):\n",
    "        return compute_BatchNorm2d_fmap(module, inp, out, passing = p)*batch_size\n",
    "    elif isinstance(module,  (nn.MaxPool2d, nn.AdaptiveAvgPool2d)):\n",
    "        return compute_Pool2d_fmap(module, inp, out, passing = p)*batch_size\n",
    "    elif isinstance(module, (nn.ReLU, nn.ReLU6, nn.ELU, nn.LeakyReLU, nn.Tanh, nn.Softplus, nn.Sigmoid, nn.Softmax)):\n",
    "        return compute_ReLU_fmap(module, inp, out)*batch_size\n",
    "#     elif isinstance(module, nn.Upsample):\n",
    "#         return compute_Upsample_flops(module, inp, out) // 2\n",
    "    elif isinstance(module, nn.Linear):\n",
    "        return compute_Linear_fmap(module, inp, out, passing = p)*batch_size\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff07f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_interm_rep(module, inp, out, l, batch_size = 1, p = 'f'):\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        return compute_Conv2d_interm_rep(module, inp, out, layer = l, passing = p)*batch_size\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dffec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Conv2d_flops(module, _inp, _out, passing = 'f'):\n",
    "    inp = _inp.size()\n",
    "    if len(_out)>1:\n",
    "        out = torch.tensor([len(_out)]+list( _out[0].size()[0:]))\n",
    "    else:\n",
    "        out = _out[0].size()\n",
    "    assert isinstance(module, nn.Conv2d)\n",
    "    #assert len(inp) == 4 and len(inp) == len(out)\n",
    "    if isinstance(module.kernel_size, (tuple, list)):\n",
    "        kh, kw = module.kernel_size\n",
    "    else:\n",
    "        kh, kw = module.kernel_size, module.kernel_size\n",
    "    if passing == 'f':\n",
    "        if module.bias is not None:\n",
    "            add = out[3]*out[3]*kh*kw*inp[1]*out[1]\n",
    "            mul = add\n",
    "        else:\n",
    "            add = out[2]*out[3]*(kh*kw*inp[1]-1)*out[1]\n",
    "            mul = out[2]*out[3]*kh*kw*inp[1]*out[1]\n",
    "    else:\n",
    "        add = (out[2]*out[3]-1)*kh*kw*inp[1]*out[1]+out[2]*out[3]*(out[1]-1)*kh*kw*inp[1]+(out[2]*out[3]*kh*kw-inp[2]*inp[3])*inp[1]\n",
    "        mul = 2*out[2]*out[3]*kh*kw*inp[1]*out[1]\n",
    "        if module.bias is not None:\n",
    "            add += (out[2]*out[3]-1)*out[1]\n",
    "    return int(add*inp[0]), int(mul*inp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a7cff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Pool2d_flops(module, _inp, _out, passing = 'f'):\n",
    "    inp = _inp.size()\n",
    "    if len(_out)>1:\n",
    "        out = torch.tensor([len(_out)]+list( _out[0].size()[0:]))\n",
    "    else:\n",
    "        out = _out[0].size()\n",
    "    assert isinstance(module, nn.MaxPool2d)\n",
    "    #assert len(inp) == 4 and len(inp) == len(out)\n",
    "    if isinstance(module.kernel_size, (tuple, list)):\n",
    "        kh, kw = module.kernel_size\n",
    "    else:\n",
    "        kh, kw = module.kernel_size, module.kernel_size\n",
    "    if passing == 'f':\n",
    "        op = out[1]*out[2]*out[3]*(kh*kw-1)\n",
    "    else :\n",
    "        op = out[1]*out[2]*out[3]\n",
    "    return int(op*inp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b7e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_AvgPool2d_flops(module, _inp, _out, passing = 'f'):\n",
    "    inp = _inp.size()\n",
    "    if len(_out)>1:\n",
    "        out = torch.tensor([len(_out)]+list( _out[0].size()[0:]))\n",
    "    else:\n",
    "        out = _out[0].size()\n",
    "    assert isinstance(module, nn.AdaptiveAvgPool2d)\n",
    "    if passing == 'f':\n",
    "        add = out[1]*(inp[2]*inp[3]-1)\n",
    "        div = out[1]\n",
    "    else:\n",
    "        add = out[1]*inp[2]*inp[3]\n",
    "        div = out[1]\n",
    "    return int(add), int(div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c438ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Linear_flops(module, _inp, _out, passing = 'f'):\n",
    "    if len(_out)>1:\n",
    "        out = torch.tensor([len(_out), _out[0].size()[-1]])\n",
    "    else:\n",
    "        out = _out[0].size()\n",
    "    assert isinstance(module, nn.Linear)\n",
    "    #assert len(inp) == 2 and len(out) == 2\n",
    "    if passing == 'f':\n",
    "        inp = _inp.size()\n",
    "        add = out[1]*inp[-1]*out[0]\n",
    "        mul = add\n",
    "    else:\n",
    "        inp = module.weight.size()[-1]\n",
    "        add = inp*(out[1]-1)*out[0]\n",
    "        mul = 2*out[1]*inp*out[0]\n",
    "    return int(add), int(mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60bd914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ReLU_flops(module, _inp, _out, passing = 'f'):\n",
    "    inp = _inp.size()\n",
    "    if len(_out)>1:\n",
    "        out = torch.tensor([len(_out)]+ list(_out[0].size()))\n",
    "    else:\n",
    "        out = _out[0].size()\n",
    "    assert isinstance(module, (nn.ReLU, nn.ReLU6, nn.ELU, nn.LeakyReLU))\n",
    "    ans = int(torch.prod(torch.LongTensor(list(out))))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf7bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_PReLU_flops(module, _inp, _out, passing = 'f'):\n",
    "    inp = _inp.size()\n",
    "    if len(_out)>1:\n",
    "        out = torch.tensor([len(_out)]+ list(_out[0].size()))\n",
    "    else:\n",
    "        out = _out[0].size()\n",
    "    assert isinstance(module, nn.PReLU)\n",
    "    if passing == 'f':\n",
    "        log = int(torch.prod(torch.LongTensor(list(out))))\n",
    "        mul = log\n",
    "        add = 0\n",
    "    else:\n",
    "        log = 2*int(torch.prod(torch.LongTensor(list(out))))\n",
    "        mul = 1\n",
    "        add = int(torch.prod(torch.LongTensor(list(out))))-1\n",
    "    return log, mul, add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e172e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Tanh_flops(module, _inp, _out, passing = 'f'):\n",
    "    inp = _inp.size()\n",
    "    if len(_out)>1:\n",
    "        out = torch.tensor([len(_out)]+ list(_out[0].size()))\n",
    "    else:\n",
    "        out = _out[0].size()\n",
    "        assert isinstance(module, nn.Tanh)\n",
    "    if passing == 'f':\n",
    "        exp = int(torch.prod(torch.LongTensor(list(out))))\n",
    "        mul = int(torch.prod(torch.LongTensor(list(out))))\n",
    "        add = 2*int(torch.prod(torch.LongTensor(list(out))))\n",
    "        div = int(torch.prod(torch.LongTensor(list(out))))\n",
    "    else:\n",
    "        exp = 0\n",
    "        mul = int(torch.prod(torch.LongTensor(list(out))))*2\n",
    "        add = int(torch.prod(torch.LongTensor(list(out))))\n",
    "        div = 0\n",
    "    return exp, mul, add, div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348a1a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Sigmoid_flops(module, _inp, _out, passing = 'f'):\n",
    "    inp = _inp.size()\n",
    "    if len(_out)>1:\n",
    "        out = torch.tensor([len(_out)]+ list(_out[0].size()))\n",
    "    else:\n",
    "        out = _out[0].size()\n",
    "        assert isinstance(module, nn.Sigmoid)\n",
    "    if passing == 'f':\n",
    "        exp = int(torch.prod(torch.LongTensor(list(out))))\n",
    "        mul = 0\n",
    "        add = int(torch.prod(torch.LongTensor(list(out))))\n",
    "        div = int(torch.prod(torch.LongTensor(list(out))))\n",
    "    else:\n",
    "        exp = 0\n",
    "        mul = int(torch.prod(torch.LongTensor(list(out))))*2\n",
    "        add = int(torch.prod(torch.LongTensor(list(out))))\n",
    "        div = 0\n",
    "    return exp, mul, add, div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2464bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Softplus_flops(module, _inp, _out, passing = 'f'):\n",
    "    inp = _inp.size()\n",
    "    if len(_out)>1:\n",
    "        out = torch.tensor([len(_out)]+ list(_out[0].size()))\n",
    "    else:\n",
    "        out = _out[0].size()\n",
    "        assert isinstance(module, nn.Softplus)\n",
    "    if passing == 'f':\n",
    "        exp = int(torch.prod(torch.LongTensor(list(out))))\n",
    "        logar = int(torch.prod(torch.LongTensor(list(out))))\n",
    "        add = int(torch.prod(torch.LongTensor(list(out))))\n",
    "        div = 0\n",
    "    else:\n",
    "        exp = 0\n",
    "        logar = 0\n",
    "        add = 0\n",
    "        div = int(torch.prod(torch.LongTensor(list(out))))\n",
    "    return exp, logar, add, div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c6d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Softmax_flops(module, _inp, _out, passing = 'f'):\n",
    "    inp = _inp.size()\n",
    "    if len(_out)>1:\n",
    "        out = torch.tensor([len(_out)]+ list(_out[0].size()))\n",
    "    else:\n",
    "        out = _out[0].size()\n",
    "        assert isinstance(module, nn.Softmax)\n",
    "    if passing == 'f':\n",
    "        exp = out[1]\n",
    "        mul = out[1]\n",
    "        add = out[1]-1\n",
    "        inv = 1\n",
    "    else:\n",
    "        exp = 0\n",
    "        mul = out[1]-1\n",
    "        add = out[1]*2-1\n",
    "        inv = 0\n",
    "    return int(exp), int(mul), int(add), int(inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_BatchNorm2d_flops(module, _inp, _out, b_sz, passing = 'f', mode = 'train'):\n",
    "    inp = _inp.size()\n",
    "    if b_sz==1:\n",
    "        b_sz = 2\n",
    "    if passing == 'f':\n",
    "        if mode == 'train':\n",
    "            add = (2*inp[2]*inp[3]*b_sz+1)*inp[1]\n",
    "            mul = (3*inp[2]*inp[3]*b_sz+6)*inp[1]\n",
    "            sq_inv = inp[1]\n",
    "        else:\n",
    "            add = (2*inp[2]*inp[3]+1)*inp[1]*b_sz\n",
    "            mul = (inp[2]*inp[3]+1)*inp[1]*b_sz\n",
    "            sq_inv = inp[1]*b_sz\n",
    "    else :\n",
    "        add = (8*inp[2]*inp[3]*b_sz-4)*inp[1]\n",
    "        mul = (7*inp[2]*inp[3]*b_sz+8)*inp[1]\n",
    "        sq_inv = 0\n",
    "    return int(add), int(mul), int(sq_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Dropout_flops(module, _inp, _out):\n",
    "    inp = _inp.size()\n",
    "    return int(torch.prod(torch.LongTensor(list(inp))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77569825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Conv2d_params(module, _inp, _out, passing = 'f'):\n",
    "    inp = _inp.size()\n",
    "    if len(_out)>1:\n",
    "        out = torch.tensor([len(_out)]+list( _out[0].size()[0:]))\n",
    "    else:\n",
    "        out = _out[0].size()\n",
    "    if isinstance(module.kernel_size, (tuple, list)):\n",
    "        kh, kw = module.kernel_size\n",
    "    else:\n",
    "        kh, kw = module.kernel_size, module.kernel_size\n",
    "    param = kh*kw*inp[1]*out[1]\n",
    "    if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
    "        param += out[1]\n",
    "    return int(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d7e9588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Linear_params(module, _inp, _out, passing = 'f'):\n",
    "    inp = _inp.size()\n",
    "    if len(_out)>1:\n",
    "        out = torch.tensor([len(_out), _out[0].size()[-1]])\n",
    "    else:\n",
    "        out = _out[0].size()\n",
    "    assert isinstance(module, nn.Linear)\n",
    "    param = inp[1]*out[1]\n",
    "    if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
    "        param += out[1]\n",
    "    return int(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b3ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_BatchNorm2d_params(module, _inp, _out, passing = 'f'):\n",
    "    inp = _inp.size()\n",
    "    return int(2*inp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e7029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Conv2d_fmap(module, _inp, _out, layer = 0, passing = 'f'):\n",
    "    inp = _inp.size()\n",
    "    if len(_out)>1:\n",
    "        out = torch.tensor([len(_out)]+list( _out[0].size()[0:]))\n",
    "    else:\n",
    "        out = _out[0].size()\n",
    "    assert isinstance(module, nn.Conv2d)\n",
    "    #assert len(inp) == 4 and len(inp) == len(out)\n",
    "    if isinstance(module.kernel_size, (tuple, list)):\n",
    "        kh, kw = module.kernel_size\n",
    "    else:\n",
    "        kh, kw = module.kernel_size, module.kernel_size\n",
    "#     if passing=='b':\n",
    "#         print(inp)\n",
    "#         print(out)\n",
    "    if layer == 1:\n",
    "        if passing == 'f':\n",
    "            fmap = out[1]*out[2]*out[3]\n",
    "        else:\n",
    "            fmap = 0\n",
    "    else:\n",
    "        if passing == 'f':\n",
    "            fmap = out[1]*out[2]*out[3]\n",
    "        else:\n",
    "            fmap = inp[1]*inp[2]*inp[3]\n",
    "#             print(kh)\n",
    "#             print(kw)\n",
    "#             print(inp[1])\n",
    "#             print(inp[2])\n",
    "#             print(inp[3])\n",
    "#             print(out[2])\n",
    "#             print(out[3])\n",
    "#             print(fmap)\n",
    "    return int(fmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b8943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Conv2d_interm_rep(module, _inp, _out, layer = 0, passing = 'f'):\n",
    "    inp = _inp.size()\n",
    "    if len(_out)>1:\n",
    "        out = torch.tensor([len(_out)]+list( _out[0].size()[0:]))\n",
    "    else:\n",
    "        out = _out[0].size()\n",
    "    assert isinstance(module, nn.Conv2d)\n",
    "    #assert len(inp) == 4 and len(inp) == len(out)\n",
    "    if isinstance(module.kernel_size, (tuple, list)):\n",
    "        kh, kw = module.kernel_size\n",
    "    else:\n",
    "        kh, kw = module.kernel_size, module.kernel_size\n",
    "    if layer == 1:\n",
    "        if passing == 'f':\n",
    "            int_rep = out[2]*out[3]*inp[1]*kh*kw\n",
    "        else:\n",
    "            int_rep = 0\n",
    "    else:\n",
    "        if passing == 'f':\n",
    "            int_rep = out[2]*out[3]*inp[1]*kh*kw\n",
    "        else:\n",
    "            int_rep = out[2]*out[3]*kh*kw*inp[1]\n",
    "    return int(int_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "687a9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Pool2d_fmap(module, _inp, _out, passing = 'f'):\n",
    "    inp = _inp.size()\n",
    "    if len(_out)>1:\n",
    "        out = torch.tensor([len(_out)]+list( _out[0].size()[0:]))\n",
    "    else:\n",
    "        out = _out[0].size()\n",
    "    assert isinstance(module, (nn.MaxPool2d, nn.AdaptiveAvgPool2d))\n",
    "    if passing == 'f':\n",
    "        return int(out[1]*out[2]*out[3])\n",
    "    else:\n",
    "        return int(inp[1]*inp[2]*inp[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2464be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Linear_fmap(module, _inp, _out, passing = 'f'):\n",
    "    if len(_out)>1:\n",
    "        out = torch.tensor([len(_out), _out[0].size()[-1]])\n",
    "    else:\n",
    "        out = _out[0].size()\n",
    "    assert isinstance(module, nn.Linear)\n",
    "    #assert len(inp) == 2 and len(out) == 2\n",
    "    if passing == 'f':\n",
    "        inp = _inp.size()\n",
    "        return int(out[1])\n",
    "    else:\n",
    "        inp = module.weight.size()[-1]\n",
    "        return int(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c9da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ReLU_fmap(module, _inp, _out):\n",
    "    inp = _inp.size()\n",
    "    if len(_out)>1:\n",
    "        out = torch.tensor([len(_out)]+ list(_out[0].size()))\n",
    "    else:\n",
    "        out = _out[0].size()\n",
    "    assert isinstance(module, (nn.ReLU, nn.ReLU6, nn.ELU, nn.LeakyReLU, nn.Tanh, nn.Softplus, nn.Sigmoid, nn.Softmax))\n",
    "    return int(torch.prod(torch.LongTensor(list(out))))/inp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2169ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_BatchNorm2d_fmap(module, _inp, _out, passing = 'f'):\n",
    "    inp = _inp.size()\n",
    "    if passing == 'f':\n",
    "        return 2*int(torch.prod(torch.LongTensor(list(inp))))\n",
    "    else :\n",
    "        return 3*int(torch.prod(torch.LongTensor(list(inp))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
